"""
HVDC ì¼€ì´ìŠ¤ë³„ ì´ë™ íƒ€ì„ë¼ì¸ ì¶”ì  ëª¨ë“ˆ
ê° ì¼€ì´ìŠ¤ì˜ ì´ë™ ê²½ë¡œì™€ ì‹œê°„ì„ ì™„ì „ ì¶”ì 
"""

import pandas as pd
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta
import logging
from collections import defaultdict, deque

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TimelineTracker:
    """HVDC ì¼€ì´ìŠ¤ë³„ ì´ë™ íƒ€ì„ë¼ì¸ ì¶”ì ê¸°"""
    
    def __init__(self):
        self.case_timelines = {}  # case_id -> timeline
        self.location_history = defaultdict(list)  # case_id -> location history
        self.movement_chains = defaultdict(list)  # case_id -> movement chain
        self.timeline_rules = {
            'max_timeline_days': 365,  # ìµœëŒ€ ì¶”ì  ê¸°ê°„
            'movement_gap_hours': 24,  # ì´ë™ ê°„ê²© ì„ê³„ê°’
            'location_validation': True,  # ìœ„ì¹˜ ìœ íš¨ì„± ê²€ì¦
        }
        
    def create_case_timeline(self, transactions: List[Dict]) -> Dict[str, List[Dict]]:
        """ì¼€ì´ìŠ¤ë³„ íƒ€ì„ë¼ì¸ ìƒì„±"""
        logger.info(f"ğŸ“… ì¼€ì´ìŠ¤ë³„ íƒ€ì„ë¼ì¸ ìƒì„± ì‹œì‘: {len(transactions)}ê±´")
        
        # ì¼€ì´ìŠ¤ë³„ íŠ¸ëœì­ì…˜ ê·¸ë£¹í™”
        case_groups = self._group_by_case_id(transactions)
        
        timelines = {}
        
        for case_id, case_transactions in case_groups.items():
            # ì‹œê°„ìˆœ ì •ë ¬
            sorted_transactions = sorted(
                case_transactions, 
                key=lambda x: self._extract_datetime(x)
            )
            
            # íƒ€ì„ë¼ì¸ ìƒì„±
            timeline = self._build_case_timeline(case_id, sorted_transactions)
            timelines[case_id] = timeline
            
        logger.info(f"âœ… íƒ€ì„ë¼ì¸ ìƒì„± ì™„ë£Œ: {len(timelines)}ê°œ ì¼€ì´ìŠ¤")
        return timelines
    
    def _group_by_case_id(self, transactions: List[Dict]) -> Dict[str, List[Dict]]:
        """ì¼€ì´ìŠ¤ IDë³„ë¡œ íŠ¸ëœì­ì…˜ ê·¸ë£¹í™”"""
        groups = defaultdict(list)
        
        for transaction in transactions:
            case_id = self._extract_case_id(transaction)
            if case_id:
                groups[case_id].append(transaction)
                
        return dict(groups)
    
    def _extract_case_id(self, transaction: Dict) -> Optional[str]:
        """íŠ¸ëœì­ì…˜ì—ì„œ ì¼€ì´ìŠ¤ ID ì¶”ì¶œ"""
        data = transaction.get('data', {})
        
        # ì—¬ëŸ¬ í•„ë“œì—ì„œ ì¼€ì´ìŠ¤ ID ì°¾ê¸°
        case_fields = ['Case', 'case_id', 'CaseID', 'ID', 'SerialNumber', 'Part']
        
        for field in case_fields:
            if field in data and data[field]:
                return str(data[field])
                
        # íŒŒì¼ëª…ì—ì„œ ì¼€ì´ìŠ¤ ì •ë³´ ì¶”ì¶œ ì‹œë„
        source_file = transaction.get('source_file', '')
        if 'case' in source_file.lower():
            # íŒŒì¼ëª… ê¸°ë°˜ ì¼€ì´ìŠ¤ ID ìƒì„±
            return f"FILE_{source_file.split('.')[0]}"
            
        return None
    
    def _extract_datetime(self, transaction: Dict) -> datetime:
        """íŠ¸ëœì­ì…˜ì—ì„œ ë‚ ì§œ/ì‹œê°„ ì¶”ì¶œ"""
        data = transaction.get('data', {})
        
        # ë‚ ì§œ í•„ë“œë“¤ í™•ì¸
        date_fields = ['date', 'timestamp', 'Date', 'Timestamp']
        
        for field in date_fields:
            if field in data and data[field]:
                try:
                    if isinstance(data[field], datetime):
                        return data[field]
                    elif isinstance(data[field], str):
                        return pd.to_datetime(data[field])
                except:
                    continue
                    
        # ê¸°ë³¸ê°’: í˜„ì¬ ì‹œê°„
        return datetime.now()
    
    def _build_case_timeline(self, case_id: str, transactions: List[Dict]) -> List[Dict]:
        """ë‹¨ì¼ ì¼€ì´ìŠ¤ì˜ íƒ€ì„ë¼ì¸ êµ¬ì¶•"""
        timeline = []
        
        for i, transaction in enumerate(transactions):
            timeline_entry = {
                'sequence': i + 1,
                'case_id': case_id,
                'timestamp': self._extract_datetime(transaction),
                'location': self._extract_location(transaction),
                'action': self._determine_action(transaction),
                'quantity': self._extract_quantities(transaction),
                'source': transaction.get('source_file', ''),
                'raw_data': transaction['data']
            }
            
            # ì´ì „ ìœ„ì¹˜ì™€ ë¹„êµí•˜ì—¬ ì´ë™ ê°ì§€
            if i > 0:
                prev_location = timeline[i-1]['location']
                curr_location = timeline_entry['location']
                
                if prev_location != curr_location:
                    timeline_entry['movement'] = {
                        'from': prev_location,
                        'to': curr_location,
                        'duration': self._calculate_duration(timeline[i-1], timeline_entry)
                    }
                    
            timeline.append(timeline_entry)
            
        return timeline
    
    def _extract_location(self, transaction: Dict) -> str:
        """íŠ¸ëœì­ì…˜ì—ì„œ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ"""
        data = transaction.get('data', {})
        
        # ìœ„ì¹˜ í•„ë“œë“¤ ìš°ì„ ìˆœìœ„ë³„ í™•ì¸
        location_fields = ['warehouse', 'site', 'location', 'from', 'to']
        
        for field in location_fields:
            if field in data and data[field]:
                return str(data[field])
                
        return 'UNKNOWN'
    
    def _determine_action(self, transaction: Dict) -> str:
        """íŠ¸ëœì­ì…˜ ì•¡ì…˜ ìœ í˜• ê²°ì •"""
        data = transaction.get('data', {})
        
        incoming = data.get('incoming', 0)
        outgoing = data.get('outgoing', 0)
        
        if incoming > 0 and outgoing == 0:
            return 'INBOUND'
        elif outgoing > 0 and incoming == 0:
            return 'OUTBOUND'
        elif incoming > 0 and outgoing > 0:
            return 'TRANSFER'
        else:
            return 'STATUS_CHECK'
    
    def _extract_quantities(self, transaction: Dict) -> Dict[str, float]:
        """ìˆ˜ëŸ‰ ì •ë³´ ì¶”ì¶œ"""
        data = transaction.get('data', {})
        
        return {
            'incoming': data.get('incoming', 0),
            'outgoing': data.get('outgoing', 0),
            'inventory': data.get('inventory', 0)
        }
    
    def _calculate_duration(self, prev_entry: Dict, curr_entry: Dict) -> Dict[str, Any]:
        """ì´ë™ ì†Œìš” ì‹œê°„ ê³„ì‚°"""
        prev_time = prev_entry['timestamp']
        curr_time = curr_entry['timestamp']
        
        duration = curr_time - prev_time
        
        return {
            'total_seconds': duration.total_seconds(),
            'hours': duration.total_seconds() / 3600,
            'days': duration.days,
            'human_readable': str(duration)
        }
    
    def analyze_movement_patterns(self, timelines: Dict[str, List[Dict]]) -> Dict[str, Any]:
        """ì´ë™ íŒ¨í„´ ë¶„ì„"""
        logger.info("ğŸ“Š ì´ë™ íŒ¨í„´ ë¶„ì„ ì‹œì‘")
        
        movement_stats = {
            'total_cases': len(timelines),
            'total_movements': 0,
            'location_frequency': defaultdict(int),
            'movement_routes': defaultdict(int),
            'average_stay_duration': {},
            'movement_velocity': []
        }
        
        for case_id, timeline in timelines.items():
            for entry in timeline:
                # ìœ„ì¹˜ ë¹ˆë„ ê³„ì‚°
                location = entry['location']
                movement_stats['location_frequency'][location] += 1
                
                # ì´ë™ ê²½ë¡œ ê³„ì‚°
                if 'movement' in entry:
                    movement_stats['total_movements'] += 1
                    route = f"{entry['movement']['from']} â†’ {entry['movement']['to']}"
                    movement_stats['movement_routes'][route] += 1
                    
                    # ì´ë™ ì†ë„ ê³„ì‚°
                    duration_hours = entry['movement']['duration']['hours']
                    if duration_hours > 0:
                        movement_stats['movement_velocity'].append(duration_hours)
                        
        # í†µê³„ ê³„ì‚°
        if movement_stats['movement_velocity']:
            movement_stats['avg_movement_time'] = sum(movement_stats['movement_velocity']) / len(movement_stats['movement_velocity'])
            movement_stats['fastest_movement'] = min(movement_stats['movement_velocity'])
            movement_stats['slowest_movement'] = max(movement_stats['movement_velocity'])
            
        logger.info(f"âœ… ì´ë™ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ: {movement_stats['total_movements']}ê±´ ì´ë™")
        return movement_stats
    
    def detect_anomalous_movements(self, timelines: Dict[str, List[Dict]]) -> List[Dict]:
        """ë¹„ì •ìƒì ì¸ ì´ë™ íŒ¨í„´ ê°ì§€"""
        logger.info("ğŸš¨ ë¹„ì •ìƒ ì´ë™ íŒ¨í„´ ê°ì§€")
        
        anomalies = []
        
        for case_id, timeline in timelines.items():
            case_anomalies = self._detect_case_anomalies(case_id, timeline)
            anomalies.extend(case_anomalies)
            
        logger.info(f"âš ï¸ ë¹„ì •ìƒ íŒ¨í„´ ê°ì§€: {len(anomalies)}ê±´")
        return anomalies
    
    def _detect_case_anomalies(self, case_id: str, timeline: List[Dict]) -> List[Dict]:
        """ë‹¨ì¼ ì¼€ì´ìŠ¤ì˜ ë¹„ì •ìƒ íŒ¨í„´ ê°ì§€"""
        anomalies = []
        
        for i, entry in enumerate(timeline):
            # 1. ìˆœê°„ì´ë™ ê°ì§€ (ë„ˆë¬´ ì§§ì€ ì‹œê°„ ë‚´ ì´ë™)
            if 'movement' in entry:
                duration_hours = entry['movement']['duration']['hours']
                if duration_hours < 0.1:  # 6ë¶„ ë¯¸ë§Œ
                    anomalies.append({
                        'case_id': case_id,
                        'type': 'INSTANT_MOVEMENT',
                        'entry': entry,
                        'reason': f'Movement in {duration_hours:.2f} hours'
                    })
                    
            # 2. ì¥ê¸° ì²´ë¥˜ ê°ì§€
            if i < len(timeline) - 1:
                next_entry = timeline[i + 1]
                if 'movement' in next_entry:
                    stay_duration = next_entry['movement']['duration']['hours']
                    if stay_duration > 24 * 30:  # 30ì¼ ì´ìƒ
                        anomalies.append({
                            'case_id': case_id,
                            'type': 'LONG_STAY',
                            'entry': entry,
                            'reason': f'Stayed {stay_duration:.1f} hours at {entry["location"]}'
                        })
                        
            # 3. ë™ì¼ ìœ„ì¹˜ ë°˜ë³µ ë°©ë¬¸
            if i > 1:
                prev_locations = [timeline[j]['location'] for j in range(max(0, i-3), i)]
                if entry['location'] in prev_locations:
                    anomalies.append({
                        'case_id': case_id,
                        'type': 'LOCATION_REVISIT',
                        'entry': entry,
                        'reason': f'Revisited {entry["location"]}'
                    })
                    
        return anomalies
    
    def generate_movement_report(self, timelines: Dict[str, List[Dict]]) -> Dict[str, Any]:
        """ì´ë™ ë¦¬í¬íŠ¸ ìƒì„±"""
        logger.info("ğŸ“‹ ì´ë™ ë¦¬í¬íŠ¸ ìƒì„±")
        
        # íŒ¨í„´ ë¶„ì„
        patterns = self.analyze_movement_patterns(timelines)
        
        # ë¹„ì •ìƒ íŒ¨í„´ ê°ì§€
        anomalies = self.detect_anomalous_movements(timelines)
        
        # ì¼€ì´ìŠ¤ë³„ ìš”ì•½
        case_summaries = {}
        for case_id, timeline in timelines.items():
            case_summaries[case_id] = self._summarize_case(timeline)
            
        report = {
            'summary': {
                'total_cases': len(timelines),
                'total_timeline_entries': sum(len(timeline) for timeline in timelines.values()),
                'analysis_timestamp': datetime.now()
            },
            'movement_patterns': patterns,
            'anomalies': {
                'count': len(anomalies),
                'types': self._categorize_anomalies(anomalies),
                'details': anomalies[:10]  # ìƒìœ„ 10ê°œë§Œ
            },
            'case_summaries': case_summaries,
            'top_locations': dict(sorted(patterns['location_frequency'].items(), 
                                       key=lambda x: x[1], reverse=True)[:10]),
            'top_routes': dict(sorted(patterns['movement_routes'].items(), 
                                    key=lambda x: x[1], reverse=True)[:10])
        }
        
        logger.info("âœ… ì´ë™ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        return report
    
    def _summarize_case(self, timeline: List[Dict]) -> Dict[str, Any]:
        """ì¼€ì´ìŠ¤ë³„ ìš”ì•½ ìƒì„±"""
        if not timeline:
            return {}
            
        movements = [entry for entry in timeline if 'movement' in entry]
        locations = list(set(entry['location'] for entry in timeline))
        
        return {
            'total_entries': len(timeline),
            'total_movements': len(movements),
            'unique_locations': len(locations),
            'start_location': timeline[0]['location'],
            'end_location': timeline[-1]['location'],
            'timeline_duration': {
                'start': timeline[0]['timestamp'],
                'end': timeline[-1]['timestamp'],
                'total_days': (timeline[-1]['timestamp'] - timeline[0]['timestamp']).days
            },
            'location_path': [entry['location'] for entry in timeline]
        }
    
    def _categorize_anomalies(self, anomalies: List[Dict]) -> Dict[str, int]:
        """ë¹„ì •ìƒ íŒ¨í„´ ìœ í˜•ë³„ ë¶„ë¥˜"""
        categories = defaultdict(int)
        
        for anomaly in anomalies:
            categories[anomaly['type']] += 1
            
        return dict(categories)
    
    def export_timeline_to_dataframe(self, timelines: Dict[str, List[Dict]]) -> pd.DataFrame:
        """íƒ€ì„ë¼ì¸ì„ DataFrameìœ¼ë¡œ ë³€í™˜"""
        logger.info("ğŸ“Š íƒ€ì„ë¼ì¸ DataFrame ë³€í™˜")
        
        all_entries = []
        
        for case_id, timeline in timelines.items():
            for entry in timeline:
                flat_entry = {
                    'case_id': case_id,
                    'sequence': entry['sequence'],
                    'timestamp': entry['timestamp'],
                    'location': entry['location'],
                    'action': entry['action'],
                    'incoming': entry['quantity']['incoming'],
                    'outgoing': entry['quantity']['outgoing'],
                    'inventory': entry['quantity']['inventory'],
                    'source_file': entry['source']
                }
                
                # ì´ë™ ì •ë³´ ì¶”ê°€
                if 'movement' in entry:
                    flat_entry.update({
                        'movement_from': entry['movement']['from'],
                        'movement_to': entry['movement']['to'],
                        'movement_duration_hours': entry['movement']['duration']['hours']
                    })
                else:
                    flat_entry.update({
                        'movement_from': None,
                        'movement_to': None,
                        'movement_duration_hours': None
                    })
                    
                all_entries.append(flat_entry)
                
        df = pd.DataFrame(all_entries)
        logger.info(f"âœ… DataFrame ë³€í™˜ ì™„ë£Œ: {len(df)}í–‰")
        
        return df
    
    def validate_timeline_integrity(self, timelines: Dict[str, List[Dict]]) -> Dict[str, Any]:
        """íƒ€ì„ë¼ì¸ ë¬´ê²°ì„± ê²€ì¦"""
        logger.info("ğŸ” íƒ€ì„ë¼ì¸ ë¬´ê²°ì„± ê²€ì¦")
        
        validation_results = {
            'total_cases': len(timelines),
            'valid_cases': 0,
            'invalid_cases': 0,
            'validation_errors': []
        }
        
        for case_id, timeline in timelines.items():
            is_valid, errors = self._validate_single_timeline(case_id, timeline)
            
            if is_valid:
                validation_results['valid_cases'] += 1
            else:
                validation_results['invalid_cases'] += 1
                validation_results['validation_errors'].extend(errors)
                
        validation_results['integrity_rate'] = (
            validation_results['valid_cases'] / validation_results['total_cases'] * 100
            if validation_results['total_cases'] > 0 else 0
        )
        
        logger.info(f"âœ… ë¬´ê²°ì„± ê²€ì¦ ì™„ë£Œ: {validation_results['integrity_rate']:.1f}% í†µê³¼")
        return validation_results
    
    def _validate_single_timeline(self, case_id: str, timeline: List[Dict]) -> Tuple[bool, List[str]]:
        """ë‹¨ì¼ íƒ€ì„ë¼ì¸ ê²€ì¦"""
        errors = []
        
        if not timeline:
            errors.append(f"Case {case_id}: Empty timeline")
            return False, errors
            
        # ì‹œê°„ìˆœ ì •ë ¬ í™•ì¸
        for i in range(1, len(timeline)):
            if timeline[i]['timestamp'] < timeline[i-1]['timestamp']:
                errors.append(f"Case {case_id}: Timeline not chronological at entry {i}")
                
        # ìœ„ì¹˜ ìœ íš¨ì„± í™•ì¸
        for i, entry in enumerate(timeline):
            if entry['location'] == 'UNKNOWN':
                errors.append(f"Case {case_id}: Unknown location at entry {i}")
                
        # ìˆ˜ëŸ‰ ì¼ê´€ì„± í™•ì¸
        for i, entry in enumerate(timeline):
            quantities = entry['quantity']
            if quantities['incoming'] < 0 or quantities['outgoing'] < 0:
                errors.append(f"Case {case_id}: Negative quantity at entry {i}")
                
        return len(errors) == 0, errors 