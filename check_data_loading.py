# check_data_loading.py
import pandas as pd
from hvdc_ontology_pipeline import EnhancedDataLoader, OntologyMapper

def analyze_data_loading_process():
    """ë°ì´í„° ë¡œë”© ê³¼ì •ì—ì„œ ëˆ„ë½ë˜ëŠ” ì›ì¸ ë¶„ì„"""
    print("ğŸ” ë°ì´í„° ë¡œë”© ê³¼ì • ë¶„ì„")
    print("=" * 60)
    
    filepath = "data/HVDC WAREHOUSE_HITACHI(HE).xlsx"
    
    # 1. ì›ë³¸ Excel íŒŒì¼ ì§ì ‘ ì½ê¸°
    print("ğŸ“„ 1ë‹¨ê³„: ì›ë³¸ Excel íŒŒì¼ ì§ì ‘ ë¶„ì„")
    df_raw = pd.read_excel(filepath, sheet_name=0)
    print(f"   ì›ë³¸ íŒŒì¼ ì´ í–‰ ìˆ˜: {len(df_raw)}")
    
    # Al Markaz ì»¬ëŸ¼ í™•ì¸
    markaz_col = None
    for col in df_raw.columns:
        if 'markaz' in str(col).lower():
            markaz_col = col
            break
    
    if markaz_col:
        print(f"   Al Markaz ì»¬ëŸ¼: '{markaz_col}'")
        
        # ì „ì²´ ë°ì´í„°ì—ì„œ Al Markaz ê°’ ê°œìˆ˜
        total_markaz = df_raw[markaz_col].count()
        print(f"   ì „ì²´ Al Markaz ë°ì´í„°: {total_markaz}ê°œ")
        
        # 3691 ì´ì „ê³¼ ì´í›„ ë¶„ë¦¬
        before_3691 = df_raw.iloc[:3690][markaz_col].count()
        after_3691 = df_raw.iloc[3690:][markaz_col].count()
        
        print(f"   3691 ì´ì „: {before_3691}ê°œ")
        print(f"   3691 ì´í›„: {after_3691}ê°œ")
        print(f"   3691 ì´í›„ ë¹„ìœ¨: {after_3691/total_markaz*100:.1f}%")
        
        # 3691 ì´í›„ ë°ì´í„° ìƒ˜í”Œ
        after_data = df_raw.iloc[3690:][markaz_col].dropna()
        if len(after_data) > 0:
            print(f"   3691 ì´í›„ ìƒ˜í”Œ: {after_data.head().tolist()}")
    
    # 2. EnhancedDataLoaderë¡œ ì²˜ë¦¬í•œ ê²°ê³¼ì™€ ë¹„êµ
    print(f"\nğŸ“Š 2ë‹¨ê³„: EnhancedDataLoader ì²˜ë¦¬ ê²°ê³¼ ë¹„êµ")
    
    mapper = OntologyMapper("mapping_rules_v2.4.json")
    loader = EnhancedDataLoader(mapper)
    
    # _process_warehouse_file ë©”ì„œë“œ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ì¤‘ê°„ ê³¼ì • í™•ì¸
    try:
        processed_df = loader._process_warehouse_file(filepath)
        print(f"   ì²˜ë¦¬ í›„ ì´ ì´ë²¤íŠ¸: {len(processed_df)}")
        
        # DSV Al Markaz ì´ë²¤íŠ¸ ê°œìˆ˜
        markaz_events = processed_df[processed_df['Location'] == 'DSV Al Markaz']
        print(f"   DSV Al Markaz ì´ë²¤íŠ¸: {len(markaz_events)}")
        
        # ë‚ ì§œ ë²”ìœ„ í™•ì¸
        if len(markaz_events) > 0:
            print(f"   Al Markaz ë‚ ì§œ ë²”ìœ„: {markaz_events['Date'].min()} ~ {markaz_events['Date'].max()}")
            
            # ë‚ ì§œë³„ ì´ë²¤íŠ¸ ë¶„í¬
            date_counts = markaz_events['Date'].value_counts().sort_index()
            print(f"   ë‚ ì§œë³„ ì´ë²¤íŠ¸ (ë§ˆì§€ë§‰ 5ì¼):")
            for date, count in date_counts.tail().items():
                print(f"     {date}: {count}ê±´")
        
        # 3. ì›ë³¸ê³¼ ì²˜ë¦¬ í›„ ë¹„êµ
        print(f"\nğŸ” 3ë‹¨ê³„: ë°ì´í„° ì†ì‹¤ ë¶„ì„")
        print(f"   ì›ë³¸ Al Markaz ë°ì´í„°: {total_markaz}ê°œ")
        print(f"   ì²˜ë¦¬ í›„ Al Markaz ì´ë²¤íŠ¸: {len(markaz_events)}ê°œ")
        print(f"   ì†ì‹¤ë¥ : {(total_markaz - len(markaz_events))/total_markaz*100:.1f}%")
        
        if total_markaz != len(markaz_events):
            print(f"   âš ï¸ {total_markaz - len(markaz_events)}ê°œ ë°ì´í„° ì†ì‹¤ ë°œìƒ!")
            
            # ì†ì‹¤ ì›ì¸ ì¶”ì •
            if after_3691 > 0 and len(markaz_events) < total_markaz:
                print(f"   ğŸ’¡ ì¶”ì • ì›ì¸: 3691ë²ˆ ì´í›„ {after_3691}ê°œ ë°ì´í„° ì²˜ë¦¬ ëˆ„ë½")
        
    except Exception as e:
        print(f"   âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    analyze_data_loading_process() 