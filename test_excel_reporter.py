#!/usr/bin/env python3
"""
HVDC Excel Reporter í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Excel ë¦¬í¬íŠ¸ ìƒì„± ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
í†µí•© ë§¤í•‘ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ storage_type ê¸°ë°˜ ì°½ê³ /í˜„ì¥ ë¶„ë¦¬ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
"""

import pandas as pd
from datetime import datetime
import sys
import os

# í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from config import load_expected_stock
except Exception as e:
    print(f"âš ï¸ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
    # ë¹ˆ í•¨ìˆ˜ë¡œ ëŒ€ì²´
    def load_expected_stock(as_of=None):
        return {}
        
from core.deduplication import drop_duplicate_transfers, reconcile_orphan_transfers
from core.loader import DataLoader
from excel_reporter import (
    generate_monthly_in_out_stock_report,
    generate_monthly_in_report,
    generate_monthly_trend_and_cumulative,
    validate_transaction_data,
    create_test_out_transaction,
    print_transaction_analysis,
    normalize_location_column,
    visualize_out_transactions,
    generate_excel_comprehensive_report
)
from mapping_utils import mapping_manager, add_storage_type_to_dataframe

def main():
    """Excel Reporter í…ŒìŠ¤íŠ¸ ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ HVDC Excel Reporter í…ŒìŠ¤íŠ¸ ì‹œì‘ (í†µí•© ë§¤í•‘ ì‹œìŠ¤í…œ)")
    print("=" * 70)
    
    try:
        # 1. ë°ì´í„° ë¡œë”©
        print("ğŸ“„ ë°ì´í„° ë¡œë”© ì¤‘...")
        loader = DataLoader()
        excel_files = loader.load_excel_files("data")
        
        if not excel_files:
            print("âŒ Excel íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            return False
            
        raw_transactions = loader.extract_transactions(excel_files)
        print(f"ğŸ“Š ì´ {len(raw_transactions):,}ê±´ì˜ ì›ì‹œ íŠ¸ëœì­ì…˜ ìˆ˜ì§‘")

        # 2. íŠ¸ëœì­ì…˜ DataFrame ë³€í™˜
        print("ğŸ”„ íŠ¸ëœì­ì…˜ ë³€í™˜ ì¤‘...")
        transaction_df = transactions_to_dataframe(raw_transactions)
        print(f"âœ… {len(transaction_df)}ê±´ íŠ¸ëœì­ì…˜ ìƒì„±")
        
        # âœ… í†µí•© ë§¤í•‘ìœ¼ë¡œ Storage Type ì¬ê²€ì¦ ë° ê°•ì œ ì ìš©
        print("\nğŸ”„ í†µí•© ë§¤í•‘ ê²€ì¦ ë° ì ìš©:")
        transaction_df = add_storage_type_to_dataframe(transaction_df, "Location")
        
        # ë§¤í•‘ ê²€ì¦ ê²°ê³¼ ì¶œë ¥
        validation_result = mapping_manager.validate_mapping(transaction_df)
        for storage_type, info in validation_result.items():
            print(f"   {storage_type}: {info['count']}ê±´ - {info['locations']}")

        # âœ… íŠ¸ëœì­ì…˜ ë°ì´í„° ìƒì„¸ ë¶„ì„ ì¶”ê°€
        print_transaction_analysis(transaction_df)
        
        # âœ… ë°ì´í„° ì§„ë‹¨ ë° ê¶Œì¥ì‚¬í•­
        diagnosis = validate_transaction_data(transaction_df)
        print("\nğŸ“‹ **ë°ì´í„° ì§„ë‹¨ ê²°ê³¼**:")
        print(diagnosis['recommendation'])

        # 3. ì „ì²˜ë¦¬
        print("ğŸ› ï¸ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        transaction_df = reconcile_orphan_transfers(transaction_df)
        transaction_df = drop_duplicate_transfers(transaction_df)
        print("âœ… ë°ì´í„° ê²€ì¦ ì™„ë£Œ")
        
        # 4. ì¼ë³„ ì¬ê³  ê³„ì‚°
        print("ğŸ“Š ì¼ë³„ ì¬ê³  ê³„ì‚° ì¤‘...")
        daily_stock = calculate_daily_inventory(transaction_df)
        print(f"âœ… {len(daily_stock)}ê°œ ì¼ë³„ ì¬ê³  ìŠ¤ëƒ…ìƒ· ìƒì„±")
        
        # --- [í•µì‹¬ ë°©ì–´ ì½”ë“œ: 'ì›”', 'Handling Fee' ì»¬ëŸ¼ ë³´ì¥] ---
        if 'ì›”' not in transaction_df.columns:
            transaction_df['ì›”'] = pd.to_datetime(transaction_df['Date'], errors='coerce').dt.strftime('%Y-%m')
        if 'Handling Fee' not in transaction_df.columns:
            transaction_df['Handling Fee'] = 0
        # ------------------------------------------------------

        # ëª¨ë“  ë¦¬í¬íŠ¸ í•¨ìˆ˜ëŠ” DataFrameë§Œ ë°˜í™˜
        in_df, out_df, stock_df = generate_monthly_in_out_stock_report(transaction_df)
        monthly_in_df = generate_monthly_in_report(transaction_df)
        trend_df, cumulative_df = generate_monthly_trend_and_cumulative(transaction_df)
        
        # âœ… OUT íŠ¸ëœì­ì…˜ í…ŒìŠ¤íŠ¸ ì¶”ê°€
        print("\nğŸ§ª OUT íŠ¸ëœì­ì…˜ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # 1. OUT íŠ¸ëœì­ì…˜ ê°•ì œ ìƒì„±
        out_row = {
            'Case_No': 'CASE_OUT_001',
            'Date': pd.Timestamp('2025-07-15'),
            'Location': 'DSV Indoor',          # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì°½ê³ ëª… ì‚¬ìš©
            'TxType_Refined': 'TRANSFER_OUT',  # ë˜ëŠ” 'FINAL_OUT' (Site ì¶œê³ ì‹œ)
            'Qty': 40,                         # ì„ì˜ ìˆ˜ëŸ‰
            'Source_File': 'í…ŒìŠ¤íŠ¸',
            'Loc_From': 'DSV Indoor',
            'Target_Warehouse': 'AGI',
            'Storage_Type': 'Indoor',
            'storage_type': 'Indoor'
        }
        
        # 2. DataFrameì— ì¶”ê°€
        transaction_df_with_out = pd.concat(
            [transaction_df, pd.DataFrame([out_row])],
            ignore_index=True
        )
        print(f"âœ… OUT íŠ¸ëœì­ì…˜ ì¶”ê°€: {out_row['Location']}ì—ì„œ {out_row['Qty']}ê°œ ì¶œê³ ")
        
        # 3. OUT í¬í•¨ ì§‘ê³„ í•¨ìˆ˜ ì¬í˜¸ì¶œ
        in_df_with_out, out_df_with_out, stock_df_with_out = generate_monthly_in_out_stock_report(transaction_df_with_out)
        
        # 4. ê²°ê³¼ ê²€ì¦
        print("\nğŸ“Š OUT íŠ¸ëœì­ì…˜ ì§‘ê³„ ê²°ê³¼ ê²€ì¦:")
        print("OUT ì‹œíŠ¸ (ë§ˆì§€ë§‰ 3í–‰):")
        print(out_df_with_out.tail(3))
        
        print("\nì¬ê³  ì‹œíŠ¸ (ë§ˆì§€ë§‰ 3í–‰):")
        print(stock_df_with_out.tail(3))
        
        # 5. ì—‘ì…€ë¡œ ì €ì¥ (í…ŒìŠ¤íŠ¸)
        with pd.ExcelWriter("HVDC_ìµœì¢…í†µí•©ë¦¬í¬íŠ¸_OUTí…ŒìŠ¤íŠ¸.xlsx", engine='xlsxwriter') as writer:
            in_df_with_out.to_excel(writer, sheet_name='01_ì›”ë³„IN_ì°½ê³ í˜„ì¥', index=False)
            out_df_with_out.to_excel(writer, sheet_name='02_ì›”ë³„OUT_ì°½ê³ í˜„ì¥', index=False)
            stock_df_with_out.to_excel(writer, sheet_name='03_ì›”ë³„ì¬ê³ _ì°½ê³ í˜„ì¥', index=False)
        print("âœ… OUT íŠ¸ëœì­ì…˜ ì§‘ê³„ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: HVDC_ìµœì¢…í†µí•©ë¦¬í¬íŠ¸_OUTí…ŒìŠ¤íŠ¸.xlsx")
        
        # 6. ê¸°ì¡´ ë¦¬í¬íŠ¸ë„ í•¨ê»˜ ì €ì¥
        with pd.ExcelWriter("HVDC_ìµœì¢…í†µí•©ë¦¬í¬íŠ¸.xlsx", engine='xlsxwriter') as writer:
            in_df.to_excel(writer, sheet_name='01_ì›”ë³„IN_ì°½ê³ í˜„ì¥', index=False)
            out_df.to_excel(writer, sheet_name='02_ì›”ë³„OUT_ì°½ê³ í˜„ì¥', index=False)
            stock_df.to_excel(writer, sheet_name='03_ì›”ë³„ì¬ê³ _ì°½ê³ í˜„ì¥', index=False)
            monthly_in_df.to_excel(writer, sheet_name='04_ì›”ë³„IN_ì§‘ê³„', index=False)
            trend_df.to_excel(writer, sheet_name='05_ì›”ë³„INOUT_íŠ¸ë Œë“œ', index=False)
            cumulative_df.to_excel(writer, sheet_name='06_ì›”ë³„ëˆ„ì ì¬ê³ ', index=False)
        print("âœ… í•œ íŒŒì¼ì— ëª¨ë“  ë¦¬í¬íŠ¸ ì‹œíŠ¸ ì €ì¥ ì™„ë£Œ!")
        
        # ì˜ˆì‹œ: OUT íŠ¸ëœì­ì…˜ ì‹œê°í™”
        visualize_out_transactions(transaction_df)
        
        # ğŸ§ª Handling Fee ì§‘ê³„ í…ŒìŠ¤íŠ¸
        print("\nğŸ§ª Handling Fee ì§‘ê³„ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # Handling Fee ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if 'Handling Fee' in transaction_df.columns:
            handling_fee_sum = transaction_df['Handling Fee'].sum()
            if handling_fee_sum > 0:
                print(f"âœ… Handling Fee ì»¬ëŸ¼ ë°œê²¬: {len(transaction_df[transaction_df['Handling Fee'].notna()])}ê±´ì˜ ë°ì´í„°")
                
                # Handling Fee í†µê³„ ì¶œë ¥
                handling_stats = {
                    'ì´í•©': transaction_df['Handling Fee'].sum(),
                    'í‰ê· ': transaction_df['Handling Fee'].mean(),
                    'ìµœëŒ€ê°’': transaction_df['Handling Fee'].max(),
                    'ìµœì†Œê°’': transaction_df['Handling Fee'].min(),
                    'í‘œì¤€í¸ì°¨': transaction_df['Handling Fee'].std()
                }
                print("ğŸ“Š Handling Fee í†µê³„:")
                for key, value in handling_stats.items():
                    print(f"   {key}: {value:,.2f}")
                
                # ì›”ë³„ Handling Fee ì§‘ê³„ í™•ì¸
                handling_by_month = transaction_df.groupby('ì›”')['Handling Fee'].sum().reset_index()
                print(f"ğŸ“… ì›”ë³„ Handling Fee ì§‘ê³„: {len(handling_by_month)}ê°œì›”")
                print(f"   ìµœê³  ì›”: {handling_by_month.loc[handling_by_month['Handling Fee'].idxmax(), 'ì›”']} ({handling_by_month['Handling Fee'].max():,.2f})")
                print(f"   ìµœì € ì›”: {handling_by_month.loc[handling_by_month['Handling Fee'].idxmin(), 'ì›”']} ({handling_by_month['Handling Fee'].min():,.2f})")
                
                # ì°½ê³ ë³„ Handling Fee ì§‘ê³„ í™•ì¸
                location_handling = transaction_df.groupby('Location')['Handling Fee'].sum().sort_values(ascending=False)
                print(f"ğŸ¢ ì°½ê³ ë³„ Handling Fee ì§‘ê³„: {len(location_handling)}ê°œ ì°½ê³ /í˜„ì¥")
                print(f"   ìµœê³  ì°½ê³ : {location_handling.index[0]} ({location_handling.iloc[0]:,.2f})")
                print(f"   ìµœì € ì°½ê³ : {location_handling.index[-1]} ({location_handling.iloc[-1]:,.2f})")
            else:
                print("âš ï¸ Handling Fee ì»¬ëŸ¼ì€ ìˆì§€ë§Œ ëª¨ë“  ê°’ì´ 0ì…ë‹ˆë‹¤!")
                print("   â†’ ì›ë³¸ Excel íŒŒì¼ì— Handling Fee ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                print("   â†’ í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ì—¬ ê¸°ëŠ¥ì„ ê²€ì¦í•©ë‹ˆë‹¤.")
                
                # í…ŒìŠ¤íŠ¸ìš© Handling Fee ë°ì´í„° ì¶”ê°€
                import random
                transaction_df['Handling Fee'] = [random.uniform(100, 1000) for _ in range(len(transaction_df))]
                print(f"âœ… í…ŒìŠ¤íŠ¸ìš© Handling Fee ë°ì´í„° ì¶”ê°€: {len(transaction_df)}ê±´")
                
                # Handling Fee í†µê³„ ì¶œë ¥
                handling_stats = {
                    'ì´í•©': transaction_df['Handling Fee'].sum(),
                    'í‰ê· ': transaction_df['Handling Fee'].mean(),
                    'ìµœëŒ€ê°’': transaction_df['Handling Fee'].max(),
                    'ìµœì†Œê°’': transaction_df['Handling Fee'].min(),
                    'í‘œì¤€í¸ì°¨': transaction_df['Handling Fee'].std()
                }
                print("ğŸ“Š í…ŒìŠ¤íŠ¸ Handling Fee í†µê³„:")
                for key, value in handling_stats.items():
                    print(f"   {key}: {value:,.2f}")
        else:
            print("â„¹ï¸ Handling Fee ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.")
            
            # í…ŒìŠ¤íŠ¸ìš© Handling Fee ë°ì´í„° ì¶”ê°€
            import random
            transaction_df['Handling Fee'] = [random.uniform(100, 1000) for _ in range(len(transaction_df))]
            print(f"âœ… í…ŒìŠ¤íŠ¸ìš© Handling Fee ë°ì´í„° ì¶”ê°€: {len(transaction_df)}ê±´")
            
            # Handling Fee í†µê³„ ì¶œë ¥
            handling_stats = {
                'ì´í•©': transaction_df['Handling Fee'].sum(),
                'í‰ê· ': transaction_df['Handling Fee'].mean(),
                'ìµœëŒ€ê°’': transaction_df['Handling Fee'].max(),
                'ìµœì†Œê°’': transaction_df['Handling Fee'].min(),
                'í‘œì¤€í¸ì°¨': transaction_df['Handling Fee'].std()
            }
            print("ğŸ“Š í…ŒìŠ¤íŠ¸ Handling Fee í†µê³„:")
            for key, value in handling_stats.items():
                print(f"   {key}: {value:,.2f}")
        
        # Handling Fee í¬í•¨í•œ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
        print("\nğŸ“Š Handling Fee í¬í•¨ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        final_report_path = f"HVDC_ìµœì¢…í†µí•©ë¦¬í¬íŠ¸_HandlingFeeí¬í•¨_{timestamp}.xlsx"
        
        # ğŸ†• NEW: ê°€ì´ë“œì— ë”°ë¼ generate_excel_comprehensive_report í•¨ìˆ˜ í˜¸ì¶œ
        generate_excel_comprehensive_report(transaction_df, daily_stock=None, output_file=final_report_path, debug=True)
        
        print(f"âœ… Handling Fee í¬í•¨ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {final_report_path}")
        
        return True
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def transactions_to_dataframe(transactions):
    """íŠ¸ëœì­ì…˜ ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ (í†µí•© ë§¤í•‘ ì ìš©)"""
    data = []
    
    for tx in transactions:
        tx_data = tx.get('data', {})
        
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        case_id = extract_case_id(tx_data)
        warehouse = extract_warehouse(tx_data)
        date_val = extract_datetime(tx_data)
        
        # âœ… í†µí•© ë§¤í•‘ìœ¼ë¡œ storage_type ë¶„ë¥˜ (ê¸°ì¡´ ê°’ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ìƒì„±)
        storage_type = tx_data.get('storage_type', 'Unknown')
        
        # ğŸ†• NEW: Vendor ì •ë³´ ì¶”ì¶œ (ê°€ì´ë“œ A ì ìš©)
        vendor = extract_vendor_from_data(tx_data, tx.get('source_file', ''))
        
        # ìˆ˜ëŸ‰ ì²˜ë¦¬
        incoming = tx_data.get('incoming', 0) or 0
        outgoing = tx_data.get('outgoing', 0) or 0
        
        # ê¸°ë³¸ ë ˆì½”ë“œ í…œí”Œë¦¿
        base_record = {
            'Case_No': case_id,
            'Date': date_val,
            'Location': warehouse,
            'Source_File': tx.get('source_file', ''),
            'Loc_From': 'SOURCE',
            'Target_Warehouse': warehouse,
            'Amount': tx_data.get('amount', 0),
            'Storage_Type': storage_type,
            'storage_type': storage_type,
            'Vendor': vendor  # ğŸ†• NEW: Vendor ì»¬ëŸ¼ ì¶”ê°€
        }
        
        # IN íŠ¸ëœì­ì…˜ ìƒì„±
        if incoming > 0:
            record = base_record.copy()
            record.update({
                'TxType_Refined': 'IN',
                'Qty': int(incoming),
                'Incoming': int(incoming),
                'Outgoing': 0
            })
            data.append(record)
            
        # OUT íŠ¸ëœì­ì…˜ ìƒì„±
        if outgoing > 0:
            record = base_record.copy()
            
            # ì‚¬ì´íŠ¸ êµ¬ë¶„í•˜ì—¬ FINAL_OUT vs TRANSFER_OUT ê²°ì •
            site = extract_site(warehouse)
            tx_type = 'FINAL_OUT' if site in ['AGI', 'DAS', 'MIR', 'SHU'] else 'TRANSFER_OUT'
                
            record.update({
                'TxType_Refined': tx_type,
                'Qty': int(outgoing),
                'Loc_From': warehouse,
                'Target_Warehouse': 'DESTINATION',
                'Incoming': 0,
                'Outgoing': int(outgoing)
            })
            data.append(record)
    
    df = pd.DataFrame(data)
    if not df.empty:
        # âœ… Location ì •ê·œí™” ì ìš© (ê°€ì´ë“œ í•„ìˆ˜ ì½”ë“œ)
        df = normalize_location_column(df)
        
        # ğŸ†• NEW: Vendor ì»¬ëŸ¼ ê°•ì œ ì •ê·œí™” (ê°€ì´ë“œ A ì ìš©)
        if 'Vendor' in df.columns:
            from mapping_utils import normalize_vendor
            df['Vendor'] = df['Vendor'].apply(normalize_vendor)
        else:
            df['Vendor'] = 'UNKNOWN'
        
        # ğŸ†• NEW: Vendor ì»¬ëŸ¼ ìì²´ë¥¼ upper()ë¡œ ì •ê·œí™” (ê°€ì´ë“œ B ì ìš©)
        df['Vendor'] = df['Vendor'].astype(str).str.strip().str.upper()
        
        # ë‚ ì§œê°€ ë¹„ì–´ìˆê±°ë‚˜ íŒŒì‹± ë¶ˆê°€í•œ ê²½ìš° í˜„ì¬ ë‚ ì§œë¡œ ëŒ€ì²´
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        df['Date'] = df['Date'].fillna(pd.Timestamp.now())
        df['Billing month'] = df['Date'].dt.strftime('%Y-%m')
        df['Category'] = 'General'
        
        # âœ… í†µí•© ë§¤í•‘ ê²€ì¦ ì¶œë ¥
        print("   ì°½ê³ ë§Œ:", df[df["Storage_Type"].isin(["Indoor", "Outdoor", "dangerous_cargo"])]["Location"].unique())
        print("   í˜„ì¥ë§Œ:", df[df["Storage_Type"] == "Site"]["Location"].unique())
        
        # ğŸ†• NEW: Vendor ê²€ì¦ ì¶œë ¥ (ê°€ì´ë“œ E ì ìš©)
        vendors_found = sorted(df['Vendor'].dropna().unique().tolist())
        print(f"   ë°œê²¬ëœ Vendor: {vendors_found}")
        
    return df

def extract_case_id(data):
    """ì¼€ì´ìŠ¤ ID ì¶”ì¶œ"""
    case_fields = ['case', 'Case', 'case_id', 'CaseID', 'ID', 'carton', 'box', 'mr#']
    
    for field in case_fields:
        if field in data and data[field]:
            case_value = str(data[field]).strip()
            if case_value and case_value.lower() not in ['nan', 'none', '']:
                return case_value
    
    return f"CASE_{abs(hash(str(data))) % 100000}"

def extract_warehouse(data):
    """ì°½ê³ ëª… ì¶”ì¶œ ë° ì •ê·œí™”"""
    warehouse_fields = ['warehouse', 'Warehouse', 'site', 'Site', 'location', 'Location']
    
    for field in warehouse_fields:
        if field in data and data[field]:
            raw_warehouse = str(data[field]).strip()
            if raw_warehouse and raw_warehouse.lower() not in ['nan', 'none', '']:
                return normalize_warehouse_name(raw_warehouse)
    
    return 'UNKNOWN'

def extract_datetime(data):
    """ë‚ ì§œ/ì‹œê°„ ì¶”ì¶œ"""
    date_fields = ['date', 'Date', 'timestamp', 'Timestamp', 'datetime']
    
    for field in date_fields:
        if field in data and data[field]:
            try:
                date_value = data[field]
                if isinstance(date_value, str) and date_value.lower() in ['nan', 'none', '']:
                    continue
                return pd.to_datetime(date_value)
            except:
                continue
    
    return pd.Timestamp.now()

def normalize_warehouse_name(raw_name):
    """ì°½ê³ ëª… ì •ê·œí™” (ë§¤í•‘ ê·œì¹™ ê¸°ë°˜)"""
    if pd.isna(raw_name) or not raw_name:
        return 'UNKNOWN'
    
    # âœ… ë§¤í•‘ ê·œì¹™ì˜ ëª¨ë“  Locationìœ¼ë¡œ ì •ê·œí™”
    all_locations = []
    for locations in mapping_manager.warehouse_classification.values():
        all_locations.extend(locations)
    
    name_lower = str(raw_name).lower().strip()
    
    for location in all_locations:
        if location.lower() in name_lower or name_lower in location.lower():
            return location
    
    return str(raw_name).strip()

def extract_site(warehouse_name):
    """ì‚¬ì´íŠ¸ëª… ì¶”ì¶œ (ë§¤í•‘ ê·œì¹™ ê¸°ë°˜)"""
    if pd.isna(warehouse_name):
        return 'UNK'
    
    # âœ… Site íƒ€ì…ì¸ì§€ í™•ì¸
    if mapping_manager.classify_storage_type(warehouse_name) == 'Site':
        return warehouse_name
    
    return 'UNK'

def extract_vendor_from_data(tx_data, source_file):
    """Vendor ì •ë³´ ì¶”ì¶œ (ì›ë³¸ ë°ì´í„° ê¸°ë°˜) - ê°€ì´ë“œ B ì ìš©"""
    # HVDC CODE 3ì—ì„œ ë²¤ë” ì¶”ì¶œ
    if 'HVDC CODE 3' in tx_data:
        code3 = str(tx_data['HVDC CODE 3']).strip().upper()
        if code3 in ['HE', 'SIM']:
            return code3
    
    # íŒŒì¼ëª…ì—ì„œ ë²¤ë” ì¶”ì¶œ
    if 'HITACHI' in source_file.upper():
        return 'HE'
    elif 'SIM' in source_file.upper():
        return 'SIM'
    
    return 'UNKNOWN'

def calculate_daily_inventory(transaction_df):
    """ì¼ë³„ ì¬ê³  ê³„ì‚°"""
    if transaction_df.empty:
        return pd.DataFrame()
    
    # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì¬ê³  ê³„ì‚°
    daily_inventory = []
    
    # ì°½ê³ ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ê³„ì‚°
    for warehouse in transaction_df['Location'].unique():
        warehouse_data = transaction_df[transaction_df['Location'] == warehouse].copy()
        warehouse_data = warehouse_data.sort_values('Date')
        
        current_inventory = 0
        
        for _, row in warehouse_data.iterrows():
            # ì…ê³ /ì¶œê³ ì— ë”°ë¼ ì¬ê³  ì—…ë°ì´íŠ¸
            if row['TxType_Refined'] == 'IN':
                current_inventory += row['Qty']
            elif row['TxType_Refined'] in ['TRANSFER_OUT', 'FINAL_OUT']:
                current_inventory -= row['Qty']
            
            # ì¼ë³„ ìŠ¤ëƒ…ìƒ· ê¸°ë¡
            daily_inventory.append({
                'Date': row['Date'],
                'Location': warehouse,
                'Inventory': current_inventory,
                'Transaction_Type': row['TxType_Refined'],
                'Qty': row['Qty']
            })
    
    return pd.DataFrame(daily_inventory)

if __name__ == "__main__":
    success = main()
    if success:
        print("\nëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        sys.exit(0)
    else:
        print("\nâŒ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1) 