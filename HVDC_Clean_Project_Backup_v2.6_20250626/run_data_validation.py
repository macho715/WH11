#!/usr/bin/env python3
"""
HVDC ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì‹¤ì œ HVDC íŠ¸ëœì­ì…˜ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ì¢…í•©ì ì¸ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ìˆ˜í–‰
"""

import pandas as pd
import numpy as np
from datetime import datetime
import sys
import os

# í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸
from data_validation_engine import DataValidationEngine
from core.loader import DataLoader
from core.deduplication import drop_duplicate_transfers, reconcile_orphan_transfers
from mapping_utils import add_storage_type_to_dataframe, normalize_location_column

def load_actual_transaction_data():
    """ì‹¤ì œ HVDC íŠ¸ëœì­ì…˜ ë°ì´í„° ë¡œë“œ"""
    print("ğŸ“„ ì‹¤ì œ HVDC íŠ¸ëœì­ì…˜ ë°ì´í„° ë¡œë”© ì¤‘...")
    
    try:
        # DataLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë°ì´í„° ë¡œë“œ
        loader = DataLoader()
        excel_files = loader.load_excel_files("data")
        
        if not excel_files:
            print("âŒ Excel íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            return None
            
        raw_transactions = loader.extract_transactions(excel_files)
        print(f"ğŸ“Š ì´ {len(raw_transactions):,}ê±´ì˜ ì›ì‹œ íŠ¸ëœì­ì…˜ ìˆ˜ì§‘")

        # íŠ¸ëœì­ì…˜ DataFrame ë³€í™˜
        print("ğŸ”„ íŠ¸ëœì­ì…˜ ë³€í™˜ ì¤‘...")
        transaction_df = transactions_to_dataframe(raw_transactions)
        print(f"âœ… {len(transaction_df)}ê±´ íŠ¸ëœì­ì…˜ ìƒì„±")
        
        # í†µí•© ë§¤í•‘ ì ìš©
        print("ğŸ”„ í†µí•© ë§¤í•‘ ì ìš© ì¤‘...")
        transaction_df = add_storage_type_to_dataframe(transaction_df, "Location")
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        print("ğŸ› ï¸ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        transaction_df = reconcile_orphan_transfers(transaction_df)
        transaction_df = drop_duplicate_transfers(transaction_df)
        
        return transaction_df
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

def transactions_to_dataframe(transactions):
    """íŠ¸ëœì­ì…˜ ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
    data = []
    
    for tx in transactions:
        tx_data = tx.get('data', {})
        
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        case_id = extract_case_id(tx_data)
        warehouse = extract_warehouse(tx_data)
        date_val = extract_datetime(tx_data)
        
        # ìˆ˜ëŸ‰ ì²˜ë¦¬
        incoming = tx_data.get('incoming', 0) or 0
        outgoing = tx_data.get('outgoing', 0) or 0
        
        # ê¸°ë³¸ ë ˆì½”ë“œ í…œí”Œë¦¿
        base_record = {
            'Case_No': case_id,
            'Date': date_val,
            'Location': warehouse,
            'Source_File': tx.get('source_file', ''),
            'Loc_From': 'SOURCE',
            'Target_Warehouse': warehouse,
            'Amount': tx_data.get('amount', 0),
            'Handling Fee': tx_data.get('handling_fee', 0) or 0
        }
        
        # IN íŠ¸ëœì­ì…˜ ìƒì„±
        if incoming > 0:
            record = base_record.copy()
            record.update({
                'TxType_Refined': 'IN',
                'Qty': int(incoming),
                'Incoming': int(incoming),
                'Outgoing': 0
            })
            data.append(record)
            
        # OUT íŠ¸ëœì­ì…˜ ìƒì„±
        if outgoing > 0:
            record = base_record.copy()
            
            # ì‚¬ì´íŠ¸ êµ¬ë¶„í•˜ì—¬ FINAL_OUT vs TRANSFER_OUT ê²°ì •
            site = extract_site(warehouse)
            tx_type = 'FINAL_OUT' if site in ['AGI', 'DAS', 'MIR', 'SHU'] else 'TRANSFER_OUT'
                
            record.update({
                'TxType_Refined': tx_type,
                'Qty': int(outgoing),
                'Loc_From': warehouse,
                'Target_Warehouse': 'DESTINATION',
                'Incoming': 0,
                'Outgoing': int(outgoing)
            })
            data.append(record)
    
    df = pd.DataFrame(data)
    if not df.empty:
        # Location ì •ê·œí™” ì ìš©
        df = normalize_location_column(df)
        
        # ë‚ ì§œ ì²˜ë¦¬
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        df['Date'] = df['Date'].fillna(pd.Timestamp.now())
        df['Billing month'] = df['Date'].dt.strftime('%Y-%m')
        df['Category'] = 'General'
        
    return df

def extract_case_id(data):
    """ì¼€ì´ìŠ¤ ID ì¶”ì¶œ"""
    case_fields = ['case', 'Case', 'case_id', 'CaseID', 'ID', 'carton', 'box', 'mr#']
    
    for field in case_fields:
        if field in data and data[field]:
            case_value = str(data[field]).strip()
            if case_value and case_value.lower() not in ['nan', 'none', '']:
                return case_value
    
    return f"CASE_{abs(hash(str(data))) % 100000}"

def extract_warehouse(data):
    """ì°½ê³ ëª… ì¶”ì¶œ ë° ì •ê·œí™”"""
    warehouse_fields = ['warehouse', 'Warehouse', 'site', 'Site', 'location', 'Location']
    
    for field in warehouse_fields:
        if field in data and data[field]:
            raw_warehouse = str(data[field]).strip()
            if raw_warehouse and raw_warehouse.lower() not in ['nan', 'none', '']:
                return normalize_warehouse_name(raw_warehouse)
    
    return 'UNKNOWN'

def extract_datetime(data):
    """ë‚ ì§œ/ì‹œê°„ ì¶”ì¶œ"""
    date_fields = ['date', 'Date', 'timestamp', 'Timestamp', 'datetime']
    
    for field in date_fields:
        if field in data and data[field]:
            try:
                date_value = data[field]
                if isinstance(date_value, str) and date_value.lower() in ['nan', 'none', '']:
                    continue
                return pd.to_datetime(date_value)
            except:
                continue
    
    return pd.Timestamp.now()

def normalize_warehouse_name(raw_name):
    """ì°½ê³ ëª… ì •ê·œí™”"""
    if pd.isna(raw_name) or not raw_name:
        return 'UNKNOWN'
    
    # ë§¤í•‘ ê·œì¹™ì˜ ëª¨ë“  Locationìœ¼ë¡œ ì •ê·œí™”
    from mapping_utils import mapping_manager
    
    all_locations = []
    for locations in mapping_manager.warehouse_classification.values():
        all_locations.extend(locations)
    
    name_lower = str(raw_name).lower().strip()
    
    for location in all_locations:
        if location.lower() in name_lower or name_lower in location.lower():
            return location
    
    return str(raw_name).strip()

def extract_site(warehouse_name):
    """ì‚¬ì´íŠ¸ëª… ì¶”ì¶œ"""
    if pd.isna(warehouse_name):
        return 'UNK'
    
    # Site íƒ€ì…ì¸ì§€ í™•ì¸
    from mapping_utils import mapping_manager
    if mapping_manager.classify_storage_type(warehouse_name) == 'Site':
        return warehouse_name
    
    return 'UNK'

def run_comprehensive_validation():
    """ì¢…í•© ë°ì´í„° ê²€ì¦ ì‹¤í–‰"""
    print("ğŸ” HVDC ë°ì´í„° í’ˆì§ˆ ì¢…í•© ê²€ì¦ ì‹œì‘")
    print("=" * 70)
    
    try:
        # 1. ì‹¤ì œ ë°ì´í„° ë¡œë“œ
        transaction_df = load_actual_transaction_data()
        
        if transaction_df is None:
            print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
            return False
        
        print(f"\nğŸ“Š ë¡œë“œëœ ë°ì´í„° í˜„í™©:")
        print(f"   ì´ ë ˆì½”ë“œ: {len(transaction_df):,}ê±´")
        print(f"   ê¸°ê°„: {transaction_df['Date'].min().strftime('%Y-%m-%d')} ~ {transaction_df['Date'].max().strftime('%Y-%m-%d')}")
        print(f"   ì°½ê³ /í˜„ì¥ ìˆ˜: {transaction_df['Location'].nunique()}ê°œ")
        print(f"   íŠ¸ëœì­ì…˜ íƒ€ì…: {transaction_df['TxType_Refined'].value_counts().to_dict()}")
        
        # 2. ë°ì´í„° ê²€ì¦ ì—”ì§„ ì´ˆê¸°í™” ë° ì‹¤í–‰
        print("\nğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹œì‘...")
        validator = DataValidationEngine()
        validation_results = validator.validate_complete_dataset(transaction_df)
        
        # 3. ê²€ì¦ ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½:")
        print(f"   ë°ì´í„° í’ˆì§ˆ ì ìˆ˜: {validation_results['data_quality_score']}/100")
        print(f"   í¬ë¦¬í‹°ì»¬ ì´ìŠˆ: {len(validation_results['critical_issues'])}ê°œ")
        print(f"   ê²½ê³  ì‚¬í•­: {len(validation_results['warnings'])}ê°œ")
        print(f"   ê¶Œì¥ì‚¬í•­: {len(validation_results['recommendations'])}ê°œ")
        
        # 4. í’ˆì§ˆ ì ìˆ˜ì— ë”°ë¥¸ ë“±ê¸‰ ì¶œë ¥
        score = validation_results['data_quality_score']
        if score >= 90:
            grade = "ğŸŸ¢ ìš°ìˆ˜"
        elif score >= 70:
            grade = "ğŸŸ¡ ì–‘í˜¸"
        elif score >= 50:
            grade = "ğŸŸ  ë³´í†µ"
        else:
            grade = "ğŸ”´ ë¶ˆëŸ‰"
        
        print(f"   ë“±ê¸‰: {grade}")
        
        # 5. í¬ë¦¬í‹°ì»¬ ì´ìŠˆ ì¶œë ¥
        if validation_results['critical_issues']:
            print(f"\nğŸš¨ í¬ë¦¬í‹°ì»¬ ì´ìŠˆ:")
            for i, issue in enumerate(validation_results['critical_issues'], 1):
                print(f"   {i}. {issue}")
        
        # 6. ê²½ê³  ì‚¬í•­ ì¶œë ¥
        if validation_results['warnings']:
            print(f"\nâš ï¸ ê²½ê³  ì‚¬í•­:")
            for i, warning in enumerate(validation_results['warnings'], 1):
                print(f"   {i}. {warning}")
        
        # 7. ê¶Œì¥ì‚¬í•­ ì¶œë ¥
        if validation_results['recommendations']:
            print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for i, rec in enumerate(validation_results['recommendations'], 1):
                print(f"   {i}. {rec}")
        
        # 8. ìƒì„¸ ê²€ì¦ ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“‹ ìƒì„¸ ê²€ì¦ ê²°ê³¼:")
        for test_name, test_results in validation_results['validation_tests'].items():
            status = "âœ… í†µê³¼" if test_results.get('passed', True) else "âŒ ì‹¤íŒ¨"
            print(f"   {test_name.replace('_', ' ').title()}: {status}")
            
            if test_results.get('issues'):
                for issue in test_results['issues']:
                    print(f"     - {issue}")
        
        # 9. ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±
        print(f"\nğŸ“‹ ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        report_file = validator.generate_validation_report()
        
        print(f"\nâœ… ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ!")
        print(f"ğŸ“‹ ë¦¬í¬íŠ¸: {report_file}")
        
        # 10. ì¶”ê°€ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        generate_detailed_analysis_report(transaction_df, validation_results)
        
        return True
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def generate_detailed_analysis_report(transaction_df, validation_results):
    """ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    report_file = f"HVDC_ë°ì´í„°ìƒì„¸ë¶„ì„ë¦¬í¬íŠ¸_{timestamp}.md"
    
    report_content = f"""# HVDC ë°ì´í„° ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸

## ğŸ“‹ ë¶„ì„ ê°œìš”
- **ë¶„ì„ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ì´ ë ˆì½”ë“œ ìˆ˜**: {len(transaction_df):,}ê±´
- **ë°ì´í„° í’ˆì§ˆ ì ìˆ˜**: {validation_results['data_quality_score']}/100

## ğŸ“Š ë°ì´í„° í˜„í™© ë¶„ì„

### ê¸°ë³¸ í†µê³„
- **ì´ íŠ¸ëœì­ì…˜**: {len(transaction_df):,}ê±´
- **ê¸°ê°„**: {transaction_df['Date'].min().strftime('%Y-%m-%d')} ~ {transaction_df['Date'].max().strftime('%Y-%m-%d')}
- **ì´ ì¼ìˆ˜**: {(transaction_df['Date'].max() - transaction_df['Date'].min()).days}ì¼
- **ì°½ê³ /í˜„ì¥ ìˆ˜**: {transaction_df['Location'].nunique()}ê°œ

### íŠ¸ëœì­ì…˜ íƒ€ì…ë³„ ë¶„í¬
"""
    
    tx_type_counts = transaction_df['TxType_Refined'].value_counts()
    for tx_type, count in tx_type_counts.items():
        percentage = (count / len(transaction_df)) * 100
        report_content += f"- **{tx_type}**: {count:,}ê±´ ({percentage:.1f}%)\n"
    
    report_content += f"""
### ì°½ê³ /í˜„ì¥ë³„ ë¶„í¬
"""
    
    location_counts = transaction_df['Location'].value_counts().head(10)
    for location, count in location_counts.items():
        percentage = (count / len(transaction_df)) * 100
        report_content += f"- **{location}**: {count:,}ê±´ ({percentage:.1f}%)\n"
    
    report_content += f"""
### Storage Typeë³„ ë¶„í¬
"""
    
    if 'Storage_Type' in transaction_df.columns:
        storage_counts = transaction_df['Storage_Type'].value_counts()
        for storage_type, count in storage_counts.items():
            percentage = (count / len(transaction_df)) * 100
            report_content += f"- **{storage_type}**: {count:,}ê±´ ({percentage:.1f}%)\n"
    
    report_content += f"""
## ğŸ“ˆ ì‹œê°„ì  ë¶„ì„

### ì›”ë³„ íŠ¸ëœì­ì…˜ ë¶„í¬
"""
    
    # ì›”ë³„ ë¶„í¬
    transaction_df['YearMonth'] = transaction_df['Date'].dt.to_period('M')
    monthly_counts = transaction_df['YearMonth'].value_counts().sort_index()
    
    for month, count in monthly_counts.items():
        report_content += f"- **{month}**: {count:,}ê±´\n"
    
    report_content += f"""
### ìš”ì¼ë³„ íŠ¸ëœì­ì…˜ ë¶„í¬
"""
    
    # ìš”ì¼ë³„ ë¶„í¬
    transaction_df['DayOfWeek'] = transaction_df['Date'].dt.day_name()
    day_counts = transaction_df['DayOfWeek'].value_counts()
    
    for day, count in day_counts.items():
        percentage = (count / len(transaction_df)) * 100
        report_content += f"- **{day}**: {count:,}ê±´ ({percentage:.1f}%)\n"
    
    report_content += f"""
## ğŸ” ë°ì´í„° í’ˆì§ˆ ë¶„ì„

### ê²€ì¦ ê²°ê³¼ ìš”ì•½
- **í’ˆì§ˆ ì ìˆ˜**: {validation_results['data_quality_score']}/100
- **í¬ë¦¬í‹°ì»¬ ì´ìŠˆ**: {len(validation_results['critical_issues'])}ê°œ
- **ê²½ê³  ì‚¬í•­**: {len(validation_results['warnings'])}ê°œ

### ìƒì„¸ ê²€ì¦ ê²°ê³¼
"""
    
    for test_name, test_results in validation_results['validation_tests'].items():
        status = "âœ… í†µê³¼" if test_results.get('passed', True) else "âŒ ì‹¤íŒ¨"
        report_content += f"#### {test_name.replace('_', ' ').title()}: {status}\n"
        
        if test_results.get('details'):
            for key, value in test_results['details'].items():
                report_content += f"- **{key}**: {value}\n"
        
        report_content += "\n"
    
    report_content += f"""
## ğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­

### ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”
"""
    
    if validation_results['critical_issues']:
        for issue in validation_results['critical_issues']:
            report_content += f"- {issue}\n"
    else:
        report_content += "- í¬ë¦¬í‹°ì»¬ ì´ìŠˆ ì—†ìŒ\n"
    
    report_content += f"""
### ê°œì„  ê¶Œì¥ì‚¬í•­
"""
    
    if validation_results['recommendations']:
        for rec in validation_results['recommendations']:
            report_content += f"- {rec}\n"
    else:
        report_content += "- ì¶”ê°€ ê¶Œì¥ì‚¬í•­ ì—†ìŒ\n"
    
    report_content += f"""
## ğŸ“Š ìˆ˜ëŸ‰ ë° ê¸ˆì•¡ ë¶„ì„

### ìˆ˜ëŸ‰ í†µê³„
"""
    
    if 'Qty' in transaction_df.columns:
        qty_stats = transaction_df['Qty'].describe()
        report_content += f"""
- **ì´ ìˆ˜ëŸ‰**: {transaction_df['Qty'].sum():,}
- **í‰ê·  ìˆ˜ëŸ‰**: {qty_stats['mean']:.2f}
- **ìµœëŒ€ ìˆ˜ëŸ‰**: {qty_stats['max']}
- **ìµœì†Œ ìˆ˜ëŸ‰**: {qty_stats['min']}
- **í‘œì¤€í¸ì°¨**: {qty_stats['std']:.2f}
"""
    
    report_content += f"""
### Handling Fee ë¶„ì„
"""
    
    if 'Handling Fee' in transaction_df.columns:
        handling_stats = transaction_df['Handling Fee'].describe()
        report_content += f"""
- **ì´ Handling Fee**: {transaction_df['Handling Fee'].sum():,.2f}
- **í‰ê·  Handling Fee**: {handling_stats['mean']:.2f}
- **ìµœëŒ€ Handling Fee**: {handling_stats['max']:.2f}
- **ìµœì†Œ Handling Fee**: {handling_stats['min']:.2f}
- **í‘œì¤€í¸ì°¨**: {handling_stats['std']:.2f}
"""
    
    report_content += f"""
---
**ë¦¬í¬íŠ¸ ìƒì„±**: HVDC ë°ì´í„° ìƒì„¸ ë¶„ì„ ì—”ì§„ v1.0
**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"ğŸ“‹ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸: {report_file}")
    return report_file

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ HVDC ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹¤í–‰")
    print("=" * 70)
    
    success = run_comprehensive_validation()
    
    if success:
        print("\nğŸ‰ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì„±ê³µ!")
        print("ğŸ“‹ ìƒì„±ëœ ë¦¬í¬íŠ¸:")
        print("   - HVDC_ë°ì´í„°í’ˆì§ˆê²€ì¦ë¦¬í¬íŠ¸_YYYYMMDD_HHMMSS.md")
        print("   - HVDC_ë°ì´í„°ìƒì„¸ë¶„ì„ë¦¬í¬íŠ¸_YYYYMMDD_HHMMSS.md")
    else:
        print("\nâŒ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨!")
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 