#!/usr/bin/env python3
"""
HVDC ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì—”ì§„

í†µí•© ë§¤í•‘ ì‹œìŠ¤í…œ ê¸°ë°˜ ë°ì´í„° í’ˆì§ˆ ì‹¬ì¸µ ê²€ì¦
ë°ì´í„° ë¬´ê²°ì„±, ì¼ê´€ì„±, ì™„ì „ì„±, ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
from pathlib import Path
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DataValidationEngine:
    """HVDC ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì—”ì§„"""
    
    def __init__(self):
        self.validation_results = {}
        self.issues_found = []
        self.recommendations = []
        
    def validate_complete_dataset(self, transaction_df):
        """ì „ì²´ ë°ì´í„°ì…‹ ì¢…í•© ê²€ì¦"""
        logger.info("ğŸ” HVDC ë°ì´í„° í’ˆì§ˆ ì¢…í•© ê²€ì¦ ì‹œì‘")
        
        validation_summary = {
            'timestamp': datetime.now().isoformat(),
            'total_records': len(transaction_df),
            'validation_tests': {},
            'critical_issues': [],
            'warnings': [],
            'recommendations': [],
            'data_quality_score': 0
        }
        
        # 1. ê¸°ë³¸ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
        logger.info("1ï¸âƒ£ ê¸°ë³¸ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦")
        integrity_results = self.validate_data_integrity(transaction_df)
        validation_summary['validation_tests']['integrity'] = integrity_results
        
        # 2. ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦
        logger.info("2ï¸âƒ£ ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦")
        business_results = self.validate_business_rules(transaction_df)
        validation_summary['validation_tests']['business_rules'] = business_results
        
        # 3. ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
        logger.info("3ï¸âƒ£ ë°ì´í„° ì¼ê´€ì„± ê²€ì¦")
        consistency_results = self.validate_data_consistency(transaction_df)
        validation_summary['validation_tests']['consistency'] = consistency_results
        
        # 4. ì™„ì „ì„± ê²€ì¦
        logger.info("4ï¸âƒ£ ë°ì´í„° ì™„ì „ì„± ê²€ì¦")
        completeness_results = self.validate_data_completeness(transaction_df)
        validation_summary['validation_tests']['completeness'] = completeness_results
        
        # 5. í†µí•© ë§¤í•‘ ê²€ì¦
        logger.info("5ï¸âƒ£ í†µí•© ë§¤í•‘ ê²€ì¦")
        mapping_results = self.validate_mapping_integrity(transaction_df)
        validation_summary['validation_tests']['mapping'] = mapping_results
        
        # 6. ì‹œê°„ì  ì¼ê´€ì„± ê²€ì¦
        logger.info("6ï¸âƒ£ ì‹œê°„ì  ì¼ê´€ì„± ê²€ì¦")
        temporal_results = self.validate_temporal_consistency(transaction_df)
        validation_summary['validation_tests']['temporal'] = temporal_results
        
        # 7. ìˆ˜ëŸ‰ ë° ê¸ˆì•¡ ê²€ì¦
        logger.info("7ï¸âƒ£ ìˆ˜ëŸ‰ ë° ê¸ˆì•¡ ê²€ì¦")
        quantity_results = self.validate_quantities_and_amounts(transaction_df)
        validation_summary['validation_tests']['quantities'] = quantity_results
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        validation_summary['data_quality_score'] = self.calculate_quality_score(validation_summary)
        
        # í¬ë¦¬í‹°ì»¬ ì´ìŠˆ ë° ê¶Œì¥ì‚¬í•­ ìˆ˜ì§‘
        validation_summary['critical_issues'] = self.collect_critical_issues(validation_summary)
        validation_summary['warnings'] = self.collect_warnings(validation_summary)
        validation_summary['recommendations'] = self.generate_recommendations(validation_summary)
        
        self.validation_results = validation_summary
        return validation_summary
    
    def validate_data_integrity(self, df):
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        results = {
            'passed': True,
            'issues': [],
            'details': {}
        }
        
        # í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
        required_columns = ['Case_No', 'Date', 'Location', 'TxType_Refined', 'Qty']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            results['passed'] = False
            results['issues'].append(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
        
        # NULL ê°’ ê²€ì¦
        null_counts = df[required_columns].isnull().sum()
        critical_null_columns = null_counts[null_counts > 0]
        
        if not critical_null_columns.empty:
            results['issues'].append(f"NULL ê°’ ë°œê²¬: {critical_null_columns.to_dict()}")
            if critical_null_columns.max() > len(df) * 0.1:  # 10% ì´ìƒ NULL
                results['passed'] = False
        
        # ì¤‘ë³µ ë ˆì½”ë“œ ê²€ì¦
        duplicate_count = df.duplicated().sum()
        if duplicate_count > 0:
            results['issues'].append(f"ì¤‘ë³µ ë ˆì½”ë“œ: {duplicate_count}ê±´")
            if duplicate_count > len(df) * 0.05:  # 5% ì´ìƒ ì¤‘ë³µ
                results['passed'] = False
        
        results['details'] = {
            'total_records': len(df),
            'null_counts': null_counts.to_dict(),
            'duplicate_count': duplicate_count
        }
        
        return results
    
    def validate_business_rules(self, df):
        """ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦"""
        results = {
            'passed': True,
            'issues': [],
            'details': {}
        }
        
        # 1. ìˆ˜ëŸ‰ ê²€ì¦
        if 'Qty' in df.columns:
            negative_qty = (df['Qty'] < 0).sum()
            zero_qty = (df['Qty'] == 0).sum()
            
            if negative_qty > 0:
                results['issues'].append(f"ìŒìˆ˜ ìˆ˜ëŸ‰: {negative_qty}ê±´")
                results['passed'] = False
            
            if zero_qty > len(df) * 0.1:  # 10% ì´ìƒ 0ìˆ˜ëŸ‰
                results['issues'].append(f"0ìˆ˜ëŸ‰ ë¹„ìœ¨ ë†’ìŒ: {zero_qty}ê±´ ({zero_qty/len(df)*100:.1f}%)")
        
        # 2. ë‚ ì§œ ë²”ìœ„ ê²€ì¦
        if 'Date' in df.columns:
            date_range = df['Date'].agg(['min', 'max'])
            future_dates = (df['Date'] > datetime.now()).sum()
            very_old_dates = (df['Date'] < datetime(2020, 1, 1)).sum()
            
            if future_dates > 0:
                results['issues'].append(f"ë¯¸ë˜ ë‚ ì§œ: {future_dates}ê±´")
            
            if very_old_dates > 0:
                results['issues'].append(f"ê³¼ê±° ë‚ ì§œ (2020ë…„ ì´ì „): {very_old_dates}ê±´")
            
            results['details']['date_range'] = {
                'min': str(date_range['min']),
                'max': str(date_range['max']),
                'future_dates': future_dates,
                'very_old_dates': very_old_dates
            }
        
        # 3. íŠ¸ëœì­ì…˜ íƒ€ì… ê²€ì¦
        if 'TxType_Refined' in df.columns:
            valid_types = ['IN', 'TRANSFER_OUT', 'FINAL_OUT']
            invalid_types = df[~df['TxType_Refined'].isin(valid_types)]['TxType_Refined'].unique()
            
            if len(invalid_types) > 0:
                results['issues'].append(f"ì˜ëª»ëœ íŠ¸ëœì­ì…˜ íƒ€ì…: {invalid_types}")
                results['passed'] = False
        
        # 4. ì°½ê³ /í˜„ì¥ ê²€ì¦
        if 'Location' in df.columns:
            empty_locations = df['Location'].isnull().sum()
            unknown_locations = (df['Location'] == 'UNKNOWN').sum()
            
            if empty_locations > 0:
                results['issues'].append(f"ë¹ˆ Location: {empty_locations}ê±´")
            
            if unknown_locations > len(df) * 0.05:  # 5% ì´ìƒ UNKNOWN
                results['issues'].append(f"UNKNOWN Location ë¹„ìœ¨ ë†’ìŒ: {unknown_locations}ê±´")
        
        return results
    
    def validate_data_consistency(self, df):
        """ë°ì´í„° ì¼ê´€ì„± ê²€ì¦"""
        results = {
            'passed': True,
            'issues': [],
            'details': {}
        }
        
        # 1. Storage Type ì¼ê´€ì„±
        if 'Storage_Type' in df.columns and 'storage_type' in df.columns:
            inconsistent_storage = (df['Storage_Type'] != df['storage_type']).sum()
            if inconsistent_storage > 0:
                results['issues'].append(f"Storage Type ë¶ˆì¼ì¹˜: {inconsistent_storage}ê±´")
                results['passed'] = False
        
        # 2. Locationê³¼ Storage Type ì¼ê´€ì„±
        if 'Location' in df.columns and 'Storage_Type' in df.columns:
            location_storage_mapping = df.groupby('Location')['Storage_Type'].nunique()
            inconsistent_locations = location_storage_mapping[location_storage_mapping > 1]
            
            if len(inconsistent_locations) > 0:
                results['issues'].append(f"Locationë³„ Storage Type ë¶ˆì¼ì¹˜: {inconsistent_locations.to_dict()}")
        
        # 3. Case_No ì¼ê´€ì„±
        if 'Case_No' in df.columns:
            case_duplicates = df.groupby('Case_No').size()
            multiple_cases = case_duplicates[case_duplicates > 1]
            
            if len(multiple_cases) > 0:
                results['details']['case_duplicates'] = {
                    'multiple_cases_count': len(multiple_cases),
                    'max_duplicates': multiple_cases.max()
                }
        
        return results
    
    def validate_data_completeness(self, df):
        """ë°ì´í„° ì™„ì „ì„± ê²€ì¦"""
        results = {
            'passed': True,
            'issues': [],
            'details': {}
        }
        
        # 1. í•„ìˆ˜ í•„ë“œ ì™„ì „ì„±
        required_fields = ['Case_No', 'Date', 'Location', 'Qty']
        completeness_rates = {}
        
        for field in required_fields:
            if field in df.columns:
                completeness_rate = (df[field].notnull().sum() / len(df)) * 100
                completeness_rates[field] = completeness_rate
                
                if completeness_rate < 95:  # 95% ë¯¸ë§Œ ì™„ì „ì„±
                    results['issues'].append(f"{field} ì™„ì „ì„± ë‚®ìŒ: {completeness_rate:.1f}%")
                    if completeness_rate < 80:
                        results['passed'] = False
        
        # 2. ì‹œê°„ì  ì™„ì „ì„± (ì›”ë³„ ë°ì´í„° ë¶„í¬)
        if 'Date' in df.columns:
            df['YearMonth'] = df['Date'].dt.to_period('M')
            monthly_distribution = df['YearMonth'].value_counts().sort_index()
            
            # ì›”ë³„ ë°ì´í„° ë¶„í¬ ë¶„ì„
            avg_monthly_records = monthly_distribution.mean()
            std_monthly_records = monthly_distribution.std()
            
            # ë°ì´í„°ê°€ ì—†ëŠ” ì›” í™•ì¸
            date_range = pd.date_range(df['Date'].min(), df['Date'].max(), freq='M')
            missing_months = []
            for month in date_range:
                if month.to_period('M') not in monthly_distribution.index:
                    missing_months.append(str(month.to_period('M')))
            
            if missing_months:
                results['issues'].append(f"ë°ì´í„° ì—†ëŠ” ì›”: {missing_months}")
            
            results['details']['temporal_completeness'] = {
                'monthly_distribution': monthly_distribution.to_dict(),
                'avg_monthly_records': avg_monthly_records,
                'std_monthly_records': std_monthly_records,
                'missing_months': missing_months
            }
        
        results['details']['completeness_rates'] = completeness_rates
        return results
    
    def validate_mapping_integrity(self, df):
        """í†µí•© ë§¤í•‘ ê²€ì¦"""
        results = {
            'passed': True,
            'issues': [],
            'details': {}
        }
        
        # 1. Storage Type ë¶„ë¥˜ ê²€ì¦
        if 'Storage_Type' in df.columns:
            storage_type_counts = df['Storage_Type'].value_counts()
            unknown_storage = storage_type_counts.get('Unknown', 0)
            
            if unknown_storage > 0:
                results['issues'].append(f"Unknown Storage Type: {unknown_storage}ê±´")
                if unknown_storage > len(df) * 0.1:  # 10% ì´ìƒ Unknown
                    results['passed'] = False
            
            results['details']['storage_type_distribution'] = storage_type_counts.to_dict()
        
        # 2. Location ë§¤í•‘ ê²€ì¦
        if 'Location' in df.columns:
            # ë§¤í•‘ ê·œì¹™ì— ì—†ëŠ” Location í™•ì¸
            from mapping_utils import mapping_manager
            
            all_valid_locations = []
            for locations in mapping_manager.warehouse_classification.values():
                all_valid_locations.extend(locations)
            
            unmapped_locations = df[~df['Location'].isin(all_valid_locations)]['Location'].unique()
            
            if len(unmapped_locations) > 0:
                results['issues'].append(f"ë§¤í•‘ë˜ì§€ ì•Šì€ Location: {unmapped_locations}")
                results['passed'] = False
        
        return results
    
    def validate_temporal_consistency(self, df):
        """ì‹œê°„ì  ì¼ê´€ì„± ê²€ì¦"""
        results = {
            'passed': True,
            'issues': [],
            'details': {}
        }
        
        if 'Date' not in df.columns:
            return results
        
        # 1. ë‚ ì§œ ìˆœì„œ ê²€ì¦
        df_sorted = df.sort_values('Date')
        date_sequence_issues = 0
        
        # 2. ì›”ë³„ ë°ì´í„° ë¶„í¬ ê²€ì¦
        df['YearMonth'] = df['Date'].dt.to_period('M')
        monthly_counts = df['YearMonth'].value_counts().sort_index()
        
        # ê¸‰ê²©í•œ ë³€í™” ê°ì§€
        if len(monthly_counts) > 1:
            monthly_changes = monthly_counts.pct_change().abs()
            sudden_changes = monthly_changes[monthly_changes > 2.0]  # 200% ì´ìƒ ë³€í™”
            
            if len(sudden_changes) > 0:
                results['issues'].append(f"ê¸‰ê²©í•œ ì›”ë³„ ë³€í™”: {sudden_changes.to_dict()}")
        
        # 3. ì£¼ë§/ê³µíœ´ì¼ íŒ¨í„´ ê²€ì¦
        df['DayOfWeek'] = df['Date'].dt.dayofweek
        weekend_transactions = (df['DayOfWeek'] >= 5).sum()
        weekend_ratio = weekend_transactions / len(df)
        
        if weekend_ratio > 0.3:  # 30% ì´ìƒ ì£¼ë§ íŠ¸ëœì­ì…˜
            results['issues'].append(f"ì£¼ë§ íŠ¸ëœì­ì…˜ ë¹„ìœ¨ ë†’ìŒ: {weekend_ratio:.1%}")
        
        results['details']['temporal_analysis'] = {
            'total_months': len(monthly_counts),
            'weekend_ratio': weekend_ratio,
            'monthly_distribution': monthly_counts.to_dict()
        }
        
        return results
    
    def validate_quantities_and_amounts(self, df):
        """ìˆ˜ëŸ‰ ë° ê¸ˆì•¡ ê²€ì¦"""
        results = {
            'passed': True,
            'issues': [],
            'details': {}
        }
        
        # 1. ìˆ˜ëŸ‰ ê²€ì¦
        if 'Qty' in df.columns:
            qty_stats = df['Qty'].describe()
            
            # ì´ìƒì¹˜ ê²€ì¦
            q1, q3 = qty_stats['25%'], qty_stats['75%']
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            
            outliers = df[(df['Qty'] < lower_bound) | (df['Qty'] > upper_bound)]
            outlier_count = len(outliers)
            
            if outlier_count > 0:
                results['issues'].append(f"ìˆ˜ëŸ‰ ì´ìƒì¹˜: {outlier_count}ê±´")
                if outlier_count > len(df) * 0.05:  # 5% ì´ìƒ ì´ìƒì¹˜
                    results['passed'] = False
            
            results['details']['quantity_analysis'] = {
                'mean': qty_stats['mean'],
                'std': qty_stats['std'],
                'min': qty_stats['min'],
                'max': qty_stats['max'],
                'outlier_count': outlier_count
            }
        
        # 2. ê¸ˆì•¡ ê²€ì¦ (Handling Fee)
        if 'Handling Fee' in df.columns:
            handling_fee_stats = df['Handling Fee'].describe()
            
            # ìŒìˆ˜ Handling Fee ê²€ì¦
            negative_fees = (df['Handling Fee'] < 0).sum()
            if negative_fees > 0:
                results['issues'].append(f"ìŒìˆ˜ Handling Fee: {negative_fees}ê±´")
            
            results['details']['handling_fee_analysis'] = {
                'mean': handling_fee_stats['mean'],
                'std': handling_fee_stats['std'],
                'total': df['Handling Fee'].sum(),
                'negative_count': negative_fees
            }
        
        return results
    
    def calculate_quality_score(self, validation_summary):
        """ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        total_tests = len(validation_summary['validation_tests'])
        passed_tests = sum(1 for test in validation_summary['validation_tests'].values() 
                          if test.get('passed', False))
        
        base_score = (passed_tests / total_tests) * 100
        
        # í¬ë¦¬í‹°ì»¬ ì´ìŠˆì— ë”°ë¥¸ ê°ì 
        critical_penalty = len(validation_summary['critical_issues']) * 10
        warning_penalty = len(validation_summary['warnings']) * 2
        
        final_score = max(0, base_score - critical_penalty - warning_penalty)
        
        return round(final_score, 1)
    
    def collect_critical_issues(self, validation_summary):
        """í¬ë¦¬í‹°ì»¬ ì´ìŠˆ ìˆ˜ì§‘"""
        critical_issues = []
        
        for test_name, test_results in validation_summary['validation_tests'].items():
            if not test_results.get('passed', True):
                critical_issues.extend(test_results.get('issues', []))
        
        return critical_issues
    
    def collect_warnings(self, validation_summary):
        """ê²½ê³  ì‚¬í•­ ìˆ˜ì§‘"""
        warnings = []
        
        for test_name, test_results in validation_summary['validation_tests'].items():
            if test_results.get('passed', True):  # í†µê³¼í–ˆì§€ë§Œ ì£¼ì˜ì‚¬í•­ì´ ìˆëŠ” ê²½ìš°
                warnings.extend(test_results.get('issues', []))
        
        return warnings
    
    def generate_recommendations(self, validation_summary):
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ë°ì´í„° ë¬´ê²°ì„± ê¶Œì¥ì‚¬í•­
        if 'integrity' in validation_summary['validation_tests']:
            integrity_test = validation_summary['validation_tests']['integrity']
            if not integrity_test.get('passed', True):
                recommendations.append("ë°ì´í„° ë¬´ê²°ì„± ë¬¸ì œ í•´ê²° í•„ìš”: NULL ê°’ ë° ì¤‘ë³µ ë°ì´í„° ì •ë¦¬")
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê¶Œì¥ì‚¬í•­
        if 'business_rules' in validation_summary['validation_tests']:
            business_test = validation_summary['validation_tests']['business_rules']
            if not business_test.get('passed', True):
                recommendations.append("ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ìœ„ë°˜ ë°ì´í„° ê²€í†  ë° ìˆ˜ì • í•„ìš”")
        
        # ë§¤í•‘ ê¶Œì¥ì‚¬í•­
        if 'mapping' in validation_summary['validation_tests']:
            mapping_test = validation_summary['validation_tests']['mapping']
            if not mapping_test.get('passed', True):
                recommendations.append("í†µí•© ë§¤í•‘ ê·œì¹™ ì—…ë°ì´íŠ¸ í•„ìš”: ë¯¸ë§¤í•‘ Location ì¶”ê°€")
        
        # ì™„ì „ì„± ê¶Œì¥ì‚¬í•­
        if 'completeness' in validation_summary['validation_tests']:
            completeness_test = validation_summary['validation_tests']['completeness']
            if not completeness_test.get('passed', True):
                recommendations.append("ë°ì´í„° ì™„ì „ì„± ê°œì„  í•„ìš”: ëˆ„ë½ ë°ì´í„° ë³´ì™„")
        
        # í’ˆì§ˆ ì ìˆ˜ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        quality_score = validation_summary['data_quality_score']
        if quality_score < 70:
            recommendations.append("ì „ë°˜ì ì¸ ë°ì´í„° í’ˆì§ˆ ê°œì„  í•„ìš”")
        elif quality_score < 90:
            recommendations.append("ë°ì´í„° í’ˆì§ˆ ì–‘í˜¸í•˜ë‚˜ ì¼ë¶€ ê°œì„  í•„ìš”")
        else:
            recommendations.append("ë°ì´í„° í’ˆì§ˆ ìš°ìˆ˜ - ì •ê¸°ì  ëª¨ë‹ˆí„°ë§ ê¶Œì¥")
        
        return recommendations
    
    def generate_validation_report(self, output_file=None):
        """ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.validation_results:
            logger.error("ê²€ì¦ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. validate_complete_dataset()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return None
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        if output_file is None:
            output_file = f"HVDC_ë°ì´í„°í’ˆì§ˆê²€ì¦ë¦¬í¬íŠ¸_{timestamp}.md"
        
        report_content = f"""# HVDC ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë¦¬í¬íŠ¸

## ğŸ“‹ ê²€ì¦ ê°œìš”
- **ê²€ì¦ ì¼ì‹œ**: {self.validation_results['timestamp']}
- **ì´ ë ˆì½”ë“œ ìˆ˜**: {self.validation_results['total_records']:,}ê±´
- **ë°ì´í„° í’ˆì§ˆ ì ìˆ˜**: {self.validation_results['data_quality_score']}/100

## ğŸ¯ ê²€ì¦ ê²°ê³¼ ìš”ì•½

### í’ˆì§ˆ ì ìˆ˜: {self.validation_results['data_quality_score']}/100
"""
        
        # í’ˆì§ˆ ì ìˆ˜ì— ë”°ë¥¸ ë“±ê¸‰
        score = self.validation_results['data_quality_score']
        if score >= 90:
            grade = "ğŸŸ¢ ìš°ìˆ˜"
        elif score >= 70:
            grade = "ğŸŸ¡ ì–‘í˜¸"
        elif score >= 50:
            grade = "ğŸŸ  ë³´í†µ"
        else:
            grade = "ğŸ”´ ë¶ˆëŸ‰"
        
        report_content += f"**ë“±ê¸‰**: {grade}\n\n"
        
        # í¬ë¦¬í‹°ì»¬ ì´ìŠˆ
        if self.validation_results['critical_issues']:
            report_content += "## ğŸš¨ í¬ë¦¬í‹°ì»¬ ì´ìŠˆ\n"
            for issue in self.validation_results['critical_issues']:
                report_content += f"- {issue}\n"
            report_content += "\n"
        
        # ê²½ê³  ì‚¬í•­
        if self.validation_results['warnings']:
            report_content += "## âš ï¸ ê²½ê³  ì‚¬í•­\n"
            for warning in self.validation_results['warnings']:
                report_content += f"- {warning}\n"
            report_content += "\n"
        
        # ê¶Œì¥ì‚¬í•­
        if self.validation_results['recommendations']:
            report_content += "## ğŸ’¡ ê¶Œì¥ì‚¬í•­\n"
            for rec in self.validation_results['recommendations']:
                report_content += f"- {rec}\n"
            report_content += "\n"
        
        # ìƒì„¸ ê²€ì¦ ê²°ê³¼
        report_content += "## ğŸ“Š ìƒì„¸ ê²€ì¦ ê²°ê³¼\n"
        for test_name, test_results in self.validation_results['validation_tests'].items():
            status = "âœ… í†µê³¼" if test_results.get('passed', True) else "âŒ ì‹¤íŒ¨"
            report_content += f"### {test_name.replace('_', ' ').title()}: {status}\n"
            
            if test_results.get('issues'):
                report_content += "**ë°œê²¬ëœ ì´ìŠˆ**:\n"
                for issue in test_results['issues']:
                    report_content += f"- {issue}\n"
            
            if test_results.get('details'):
                report_content += "**ìƒì„¸ ì •ë³´**:\n"
                for key, value in test_results['details'].items():
                    report_content += f"- {key}: {value}\n"
            
            report_content += "\n"
        
        report_content += f"""
---
**ë¦¬í¬íŠ¸ ìƒì„±**: HVDC ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì—”ì§„ v1.0
**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"âœ… ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_file}")
        return output_file

def main():
    """ë°ì´í„° ê²€ì¦ ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ” HVDC ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì—”ì§„ ì‹œì‘")
    print("=" * 60)
    
    try:
        # ë°ì´í„° ë¡œë”©
        from test_excel_reporter import main as load_test_data
        
        print("ğŸ“„ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘...")
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© í•¨ìˆ˜ í˜¸ì¶œ
        # ì‹¤ì œë¡œëŠ” transaction_dfë¥¼ ì§ì ‘ ë¡œë“œí•´ì•¼ í•¨
        
        # ì„ì‹œë¡œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        sample_data = {
            'Case_No': ['CASE_001', 'CASE_002', 'CASE_003'],
            'Date': [datetime.now(), datetime.now(), datetime.now()],
            'Location': ['DSV Indoor', 'DSV Outdoor', 'SHU'],
            'TxType_Refined': ['IN', 'IN', 'IN'],
            'Qty': [1, 1, 1],
            'Storage_Type': ['Indoor', 'Outdoor', 'Site'],
            'storage_type': ['Indoor', 'Outdoor', 'Site']
        }
        
        transaction_df = pd.DataFrame(sample_data)
        
        # ê²€ì¦ ì—”ì§„ ì´ˆê¸°í™” ë° ì‹¤í–‰
        validator = DataValidationEngine()
        validation_results = validator.validate_complete_dataset(transaction_df)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½:")
        print(f"   ì´ ë ˆì½”ë“œ: {validation_results['total_records']:,}ê±´")
        print(f"   í’ˆì§ˆ ì ìˆ˜: {validation_results['data_quality_score']}/100")
        print(f"   í¬ë¦¬í‹°ì»¬ ì´ìŠˆ: {len(validation_results['critical_issues'])}ê°œ")
        print(f"   ê²½ê³  ì‚¬í•­: {len(validation_results['warnings'])}ê°œ")
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report_file = validator.generate_validation_report()
        
        print(f"\nâœ… ë°ì´í„° ê²€ì¦ ì™„ë£Œ!")
        print(f"ğŸ“‹ ë¦¬í¬íŠ¸: {report_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì„±ê³µ!")
    else:
        print("\nâŒ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨!") 