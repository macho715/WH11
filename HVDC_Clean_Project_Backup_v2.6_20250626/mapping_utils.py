#!/usr/bin/env python3
"""
HVDC Warehouse í†µí•© ë§¤í•‘ ìœ í‹¸ë¦¬í‹° v2.6

ë§¤í•‘ ê·œì¹™ íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ì¼ê´€ëœ Storage Type ë¶„ë¥˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ìµœì‹  ì‹¤ì „ ì˜ˆì œ ë° í™•ì¥ ìë™í™” ê¸°ëŠ¥ í¬í•¨.
"""

import json
import pandas as pd
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

# ìµœì‹  mapping_rules ë¶ˆëŸ¬ì˜¤ê¸°
try:
    with open('mapping_rules_v2.6.json', encoding='utf-8') as f:
        RULES = json.load(f)
    VENDOR_MAP = RULES['vendor_mappings']
    CONTAINER_GROUPS = RULES['container_column_groups']
    WAREHOUSE_CLASS = RULES['warehouse_classification']
    FIELD_MAP = RULES['field_map']
    PROPERTY_MAPPINGS = RULES['property_mappings']
except Exception as e:
    logger.warning(f"mapping_rules_v2.6.json ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
    VENDOR_MAP = {}
    CONTAINER_GROUPS = {}
    WAREHOUSE_CLASS = {}
    FIELD_MAP = {}
    PROPERTY_MAPPINGS = {}

class MappingManager:
    """í†µí•© ë§¤í•‘ ê´€ë¦¬ì"""
    
    def __init__(self, mapping_file: str = "mapping_rules_v2.6.json"):
        self.mapping_file = mapping_file
        self.mapping_rules = self._load_mapping_rules()
        self.warehouse_classification = self.mapping_rules.get("warehouse_classification", {})
        
    def _load_mapping_rules(self):
        """ë§¤í•‘ ê·œì¹™ íŒŒì¼ ë¡œë“œ"""
        try:
            rule_path = Path(self.mapping_file)
            if not rule_path.exists():
                logger.error(f"ë§¤í•‘ ê·œì¹™ íŒŒì¼ ì—†ìŒ: {self.mapping_file}")
                return {}
                
            with open(rule_path, "r", encoding="utf-8") as f:
                rules = json.load(f)
                logger.info(f"âœ… ë§¤í•‘ ê·œì¹™ ë¡œë“œ ì™„ë£Œ: {self.mapping_file}")
                return rules
        except Exception as e:
            logger.error(f"ë§¤í•‘ ê·œì¹™ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    def classify_storage_type(self, location: str) -> str:
        """
        Locationì„ Storage Typeìœ¼ë¡œ ë¶„ë¥˜
        
        Args:
            location: ì°½ê³ /í˜„ì¥ëª…
            
        Returns:
            str: Storage Type (Indoor, Outdoor, Site, dangerous_cargo, Unknown)
        """
        if not location or pd.isna(location):
            return "Unknown"
            
        loc = str(location).strip()
        
        # ë§¤í•‘ ê·œì¹™ì— ë”°ë¥¸ ë¶„ë¥˜
        for storage_type, locations in self.warehouse_classification.items():
            if loc in locations:
                return storage_type
                
        # ì¶”ê°€ íŒ¨í„´ ë§¤ì¹­ (ë¶€ë¶„ ë¬¸ìì—´)
        loc_lower = loc.lower()
        for storage_type, locations in self.warehouse_classification.items():
            for pattern in locations:
                if pattern.lower() in loc_lower or loc_lower in pattern.lower():
                    return storage_type
        
        logger.warning(f"âš ï¸ ë§¤í•‘ë˜ì§€ ì•Šì€ Location: {location}")
        return "Unknown"
    
    def add_storage_type_to_dataframe(self, df: pd.DataFrame, location_col: str = "Location") -> pd.DataFrame:
        """
        DataFrameì— Storage_Type ì»¬ëŸ¼ ì¶”ê°€
        
        Args:
            df: ëŒ€ìƒ DataFrame
            location_col: Location ì»¬ëŸ¼ëª…
            
        Returns:
            pd.DataFrame: Storage_Type ì»¬ëŸ¼ì´ ì¶”ê°€ëœ DataFrame
        """
        if location_col not in df.columns:
            logger.error(f"Location ì»¬ëŸ¼ ì—†ìŒ: {location_col}")
            df['Storage_Type'] = 'Unknown'
            return df
            
        # âœ… Location ê¸°ì¤€ìœ¼ë¡œ Storage_Type ìƒˆë¡œ ìƒì„± (ê¸°ì¡´ ê°’ ë¬´ì‹œ)
        df['Storage_Type'] = df[location_col].apply(self.classify_storage_type)
        
        # ê²€ì¦ ë¡œê·¸
        storage_counts = df['Storage_Type'].value_counts()
        logger.info(f"ğŸ·ï¸ Storage Type ë¶„ë¥˜ ê²°ê³¼: {dict(storage_counts)}")
        
        return df
    
    def validate_mapping(self, df: pd.DataFrame, location_col: str = "Location") -> dict:
        """
        ë§¤í•‘ ê²€ì¦ ë° í†µê³„
        
        Args:
            df: ê²€ì¦í•  DataFrame
            location_col: Location ì»¬ëŸ¼ëª…
            
        Returns:
            dict: ê²€ì¦ ê²°ê³¼
        """
        if location_col not in df.columns:
            return {"error": f"Location ì»¬ëŸ¼ ì—†ìŒ: {location_col}"}
            
        # Storage Typeë³„ ê³ ìœ  Location ëª©ë¡
        validation_result = {}
        
        for storage_type in self.warehouse_classification.keys():
            locations = df[df['Storage_Type'] == storage_type][location_col].unique()
            validation_result[storage_type] = {
                'count': len(df[df['Storage_Type'] == storage_type]),
                'locations': sorted(locations.tolist())
            }
        
        # Unknown íƒ€ì… ê²€ì¦
        unknown_locations = df[df['Storage_Type'] == 'Unknown'][location_col].unique()
        validation_result['Unknown'] = {
            'count': len(df[df['Storage_Type'] == 'Unknown']),
            'locations': sorted(unknown_locations.tolist())
        }
        
        return validation_result
    
    def get_warehouse_locations(self) -> list:
        """ì°½ê³  Location ëª©ë¡ ë°˜í™˜"""
        warehouse_types = ['Indoor', 'Outdoor', 'dangerous_cargo']
        warehouse_locations = []
        
        for storage_type in warehouse_types:
            if storage_type in self.warehouse_classification:
                warehouse_locations.extend(self.warehouse_classification[storage_type])
                
        return warehouse_locations
    
    def get_site_locations(self) -> list:
        """í˜„ì¥ Location ëª©ë¡ ë°˜í™˜"""
        return self.warehouse_classification.get('Site', [])

# ì „ì—­ ë§¤í•‘ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
mapping_manager = MappingManager()

def classify_storage_type(location: str) -> str:
    """í¸ì˜ í•¨ìˆ˜: Locationì„ Storage Typeìœ¼ë¡œ ë¶„ë¥˜"""
    return mapping_manager.classify_storage_type(location)

def add_storage_type_to_dataframe(df: pd.DataFrame, location_col: str = "Location") -> pd.DataFrame:
    """í¸ì˜ í•¨ìˆ˜: DataFrameì— Storage_Type ì»¬ëŸ¼ ì¶”ê°€"""
    return mapping_manager.add_storage_type_to_dataframe(df, location_col)

def normalize_vendor(vendor_name):
    """
    ë²¤ë”ëª… ì •ê·œí™” (mapping_rulesì˜ vendor_mappings ì ìš©)
    
    Args:
        vendor_name: ì›ë³¸ ë²¤ë”ëª…
        
    Returns:
        str: ì •ê·œí™”ëœ ë²¤ë”ëª…
    """
    if pd.isna(vendor_name) or not vendor_name:
        return 'UNKNOWN'
    
    vendor_mappings = mapping_manager.mapping_rules.get('vendor_mappings', {})
    vendor_str = str(vendor_name).strip().upper()
    
    # ë§¤í•‘ ê·œì¹™ì— ë”°ë¥¸ ì •ê·œí™”
    for original, normalized in vendor_mappings.items():
        if vendor_str == original.upper() or vendor_str in original.upper():
            return normalized
    
    return vendor_str

def standardize_container_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì»¨í…Œì´ë„ˆ ì»¬ëŸ¼ í‘œì¤€í™” (mapping_rulesì˜ container_column_groups ì ìš©)
    
    Args:
        df: ëŒ€ìƒ DataFrame
        
    Returns:
        pd.DataFrame: í‘œì¤€í™”ëœ DataFrame
    """
    container_groups = mapping_manager.mapping_rules.get('container_column_groups', {})
    
    # ê° ì»¨í…Œì´ë„ˆ ê·¸ë£¹ë³„ë¡œ í‘œì¤€í™”
    for standard_name, variations in container_groups.items():
        # í•´ë‹¹ ê·¸ë£¹ì˜ ëª¨ë“  ë³€í˜•ì„ ì°¾ì•„ì„œ í‘œì¤€ëª…ìœ¼ë¡œ í†µí•©
        for variation in variations:
            if variation in df.columns:
                # í‘œì¤€ëª… ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìƒì„±
                if standard_name not in df.columns:
                    df[standard_name] = 0
                
                # ê¸°ì¡´ ê°’ë“¤ì„ í‘œì¤€ëª… ì»¬ëŸ¼ì— ì¶”ê°€
                df[standard_name] = df[standard_name] + df[variation].fillna(0)
                
                # ì›ë³¸ ì»¬ëŸ¼ ì‚­ì œ (ì„ íƒì‚¬í•­)
                # df = df.drop(columns=[variation])
    
    return df

# ìµœì‹  ì‹¤ì „ ì˜ˆì œ í•¨ìˆ˜ë“¤ ì¶”ê°€
def normalize_vendor_enhanced(val):
    """ë²¤ë”ëª… í‘œì¤€í™”: SIMENSEâ†’SIM ë“± (ìµœì‹  ì‹¤ì „ ì˜ˆì œ)"""
    if pd.isna(val): 
        return 'Unknown'
    sval = str(val).upper()
    return VENDOR_MAP.get(sval, sval)

def standardize_container_columns_enhanced(df):
    """ì»¨í…Œì´ë„ˆ ì»¬ëŸ¼(20FT/40FT ë“±) ê·¸ë£¹í™” (ìµœì‹  ì‹¤ì „ ì˜ˆì œ)"""
    for std_col, variants in CONTAINER_GROUPS.items():
        df[std_col] = 0
        for var in variants:
            for col in df.columns:
                if col.replace(" ", "").replace("-", "").upper() == var.replace(" ", "").replace("-", "").upper():
                    df[std_col] += pd.to_numeric(df[col], errors='coerce').fillna(0)
    return df

def add_storage_type_to_dataframe_enhanced(df, col="Category"):
    """ì°½ê³ /í˜„ì¥/ìœ„í—˜ë¬¼ ìë™ ë¶„ë¥˜ (Storage_Type ë¶€ì—¬) (ìµœì‹  ì‹¤ì „ ì˜ˆì œ)"""
    def map_type(loc):
        for k, vlist in WAREHOUSE_CLASS.items():
            if str(loc).strip() in vlist:
                return k
        return "Unknown"
    df["Storage_Type"] = df[col].apply(map_type)
    return df

def normalize_location_column(df, location_col='Location'):
    """Location ì»¬ëŸ¼ ì •ê·œí™” (ìµœì‹  ì‹¤ì „ ì˜ˆì œ)"""
    df[location_col] = df[location_col].astype(str).str.strip()
    return df

def get_numeric_fields_from_mapping():
    """mapping_rulesì—ì„œ ìˆ«ìí˜• í•„ë“œ ëª©ë¡ ë°˜í™˜"""
    numeric_fields = []
    for field, props in PROPERTY_MAPPINGS.items():
        if props.get('datatype') in ['xsd:decimal', 'xsd:integer']:
            numeric_fields.append(field)
    return numeric_fields

def get_field_predicate(field_name):
    """í•„ë“œëª…ì— í•´ë‹¹í•˜ëŠ” predicate ë°˜í™˜"""
    return FIELD_MAP.get(field_name, f"has{field_name.replace(' ', '')}")

def validate_dataframe_against_mapping(df):
    """DataFrameì´ mapping_rulesì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦"""
    missing_fields = []
    extra_fields = []
    
    # mapping_rulesì— ì •ì˜ëœ í•„ë“œê°€ DataFrameì— ì—†ëŠ”ì§€ í™•ì¸
    for field in FIELD_MAP.keys():
        if field not in df.columns:
            missing_fields.append(field)
    
    # DataFrameì— ìˆì§€ë§Œ mapping_rulesì— ì •ì˜ë˜ì§€ ì•Šì€ í•„ë“œ í™•ì¸
    for col in df.columns:
        if col not in FIELD_MAP:
            extra_fields.append(col)
    
    return {
        'missing_fields': missing_fields,
        'extra_fields': extra_fields,
        'is_valid': len(missing_fields) == 0
    } 